{"prompt": "使用MindSpore做分割训练，必须将数据转为MindRecord吗？", "response": "[build_seg_data.py](https://gitee.com/mindspore/models/blob/master/official/cv/deeplabv3/src/data/build_seg_data.py)是将数据集生成MindRecord的脚本，可以直接使用/适配下你的数据集。或者如果你想尝试自己实现数据集的读取，可以使用`GeneratorDataset`自定义数据集加载。\t[GenratorDataset 示例](https://www.mindspore.cn/tutorials/zh-CN/master/advanced/dataset/custom.html)\t[GenratorDataset API说明](https://www.mindspore.cn/docs/zh-CN/master/api_python/dataset/mindspore.dataset.GeneratorDataset.html#mindspore.dataset.GeneratorDataset)", "history": []}
{"prompt": "在使用`ops.concat`算子时，因为数据规模有点大，导致报错`Error:Input and (output + workspace) num should <=192!`，可以怎么处理？", "response": "这种报错，主要为`ops.concat`算子提示`shape`过大。建议对`dataset`对象创建迭代器时可设置输出为`numpy`， 如下设置：\t```python\tgallaryloader.create_dict_iterator(output_numpy=True)\t```另外在上述后处理环节（非网络计算过程中，即非`construct`函数里面），可以采用`numpy`直接计算，如采用`numpy.concatenate`代替上述`ops.concat`进行计算。", "history": []}
{"prompt": "MindSpore安装: 版本0.6.0-beta + Ascend 910 + Ubuntu_aarch64 + Python3.7.5，手动下载对应版本的whl包，编译并安装gmp6.1.2。其他Python库依赖已经安装完成，执行样例失败，报错显示找不到so文件。", "response": "`libdatatransfer.so`动态库是`fwkacllib/lib64`目录下的，请先在`/usr/local`目录查找到这个库所在的路径，然后把这个路径加到`LD_LIBRARY_PATH`环境变量中，确认设置生效后，再执行。", "history": []}
{"prompt": "MindSpore的GPU版本对设备的计算能力有限制吗？", "response": "目前MindSpore仅支持计算能力大于5.3的设备。", "history": []}
{"prompt": "在使用`GeneratorDataset`加载数据时，报错`RuntimeError: Failed to copy data into tensor.`，怎么解决？", "response": "在使用`GeneratorDataset`加载Pyfunc返回的Numpy array时，MindSpore框架将执行Numpy array到MindSpre Tensor的转换，假设Numpy array所指向的内存被释放，可能会发生内存拷贝的错误。举例如下：\t- 在`__getitem__`函数中执行Numpy array - MindSpore Tensor - Numpy array的就地转换。其中Tensor `tensor`和Numpy array `ndarray_1`共享同一块内存，Tensor `tensor`在`__getitem__`函数退出时超出作用域，其所指向的内存将被释放。\t\t    ```python\t    class RandomAccessDataset:\t        def __init__(self):\t            pass\t\t        def __getitem__(self， item):\t            ndarray = np.zeros((544， 1056， 3))\t            tensor = Tensor.from_numpy(ndarray)\t            ndarray_1 = tensor.asnumpy()\t            return ndarray_1\t\t        def __len__(self):\t            return 8\t\t    data1 = ds.GeneratorDataset(RandomAccessDataset()， [\"data\"])\t    ```\t\t- 忽略上面例子中的循环转换，在`__getitem__`函数退出时，Tensor对象`tensor`被释放，和其共享同一块内存的Numpy array对象`ndarray_1`变成未知状态，为了规避此问题可以直接使用`deepcopy`函数为将返回的Numpy array对象`ndarray_2`申请独立的内存。\t\t    ```python\t    class RandomAccessDataset:\t        def __init__(self):\t            pass\t\t        def __getitem__(self， item):\t            ndarray = np.zeros((544， 1056， 3))\t            tensor = Tensor.from_numpy(ndarray)\t            ndarray_1 = tensor.asnumpy()\t            ndarray_2 = copy.deepcopy(ndarray_1)\t            return ndarray_2\t\t        def __len__(self):\t            return 8\t\t    data1 = ds.GeneratorDataset(RandomAccessDataset()， [\"data\"])\t    ```", "history": []}
{"prompt": "MindSpore如何加载已有的预训练词向量？", "response": "可以在定义EmbedingLookup或者Embedding时候，把预训练的词向量传进来，把预训练的词向量封装成一个Tensor作为EmbeddingLookup初始值。", "history": []}
{"prompt": "导出MindIR格式的时候，`input=np.random.uniform(...)`是不是固定格式？", "response": "不是固定格式的，这一步操作是为了创建一个输入，以便于构建网络结构。`export`里只要传入正确的`shape`即可，使用`np.ones`和`np.zeros`创建都是可以的。", "history": []}
{"prompt": "静态图下使用除法结果未报错，动态图下使用除法结果却报错？", "response": "在静态图模式下，由于使用的是静态编译，对于算子输出结果的数据类型是在图编译阶段确定的。\t例如如下代码在静态图模式下执行，输入数据的类型都为int类型，根据静态图编译，其输出结果也是int类型。\t```python\tfrom mindspore import set_context， GRAPH_MODE\tfrom mindspore import nn\t\tset_context(mode=GRAPH_MODE， device_target=\"CPU\")\t\tclass MyTest(nn.Cell):\t    def __init__(self):\t        super(MyTest， self).__init__()\t\t    def construct(self， x， y):\t        return x / y\tx = 16\ty = 4\tnet = MyTest()\toutput = net(x， y)\tprint(output， type(output))\t```输出结果：\t```text\t4 <class 'int'>\t```修改执行模式，将GRAPH_MODE修改成PYNATIVE_MODE，由于在动态图模式下使用的Python语法执行，Python语法对任意除法输出的类型都是float类型，因此执行结果如下：\t```text\t4.0 <class 'float'>\t```因此在后续算子明确需要使用int的场景下，建议使用Python的整除符号`//`。", "history": []}
{"prompt": "使用ExpandDims算子报错: `Pynative run op ExpandDims failed`。具体代码:", "response": "```python\tcontext.set_context(mode=context.GRAPH_MODE，device_target='Ascend')\tinput_tensor=Tensor(np.array([[2，2]，[2，2]])，mindspore.float32)\texpand_dims=ops.ExpandDims()\toutput=expand_dims(input_tensor，0)\t```这边的问题是选择了Graph模式却使用了PyNative的写法，所以导致报错，MindSpore支持两种运行模式，在调试或者运行方面做了不同的优化:\t- PyNative模式: 也称动态图模式，将神经网络中的各个算子逐一下发执行，方便用户编写和调试神经网络模型。\t\t- Graph模式: 也称静态图模式或者图模式，将神经网络模型编译成一整张图，然后下发执行。该模式利用图优化等技术提高运行性能，同时有助于规模部署和跨平台运行。", "history": []}
{"prompt": "在使用`Conv2D`进行卷积定义的时候使用到了`group`的参数，`group`的值不是只需要保证可以被输入输出的维度整除即可了吗？`group`参数的传递方式是怎样的呢？", "response": "`Conv2D`算子是有这个约束条件的: 当`group`大于1 时，其值必须要与输入输出的通道数相等。不要使用`ops.Conv2D`，这个算子目前不支持`group`>1。目前MindSpore只有`nn.Conv2D`接口支持组卷积，但是有`group`要与输入输出的通道数相等的约束。", "history": []}
{"prompt": "MindConverter转换TensorFlow脚本报错提示`terminate called after throwing an instance of 'std::system_error'， what(): Resource temporarily unavailable， Aborted (core dumped)`", "response": "该问题由TensorFlow导致。脚本转换时，需要通过TensorFlow库加载TensorFlow的模型文件，此时TensorFlow会申请相关资源进行初始化，若申请资源失败（可能由于系统进程数超过Linux最大进程数限制），TensorFlow C/C++层会出现Core Dumped问题。详细信息请参考TensorFlow官方ISSUE，如下ISSUE仅供参考: [TF ISSUE 14885](https://github.com/tensorflow/tensorflow/issues/14885)， [TF ISSUE 37449](https://github.com/tensorflow/tensorflow/issues/37449)", "history": []}
{"prompt": "自定义的Dataset出现错误时，应该如何调试？", "response": "自定义的Dataset通常会传入到GeneratorDataset，在使用过程中错误指向了自定义的Dataset时，可通过一些方式进行调试（如增加打印信息，打印返回值的shape、dtype等），自定义Dataset通常要保持中间处理结果为numpy array，且不建议与MindSpore网络计算的算子混合使用。此外针对自定义的Dataset如下面的MyDataset，初始化后也可直接进行如下遍历（主要为简化调试，分析原始Dataset中的问题，可不传入GeneratorDataset)，调试遵循常规的Python语法规则。\t```python\tDataset = MyDataset()\tfor item in Dataset:\t   print(\"item:\"， item)\t```", "history": []}
{"prompt": "运行应用时出现`error while loading shared libraries: libpython3.so: cannot open shared object file: No such file or directory`怎么办？", "response": "该报错通常出现在装有多个Python版本的环境中，首先确认Python的`lib`目录是否在环境变量`LD_LIBRARY_PATH`中，可执行以下命令进行设置：\t```bash\texport LD_LIBRARY_PATH=`python -c \"import distutils.sysconfig as sysconfig; print(sysconfig.get_config_var('LIBDIR'))\"`:$LD_LIBRARY_PATH\t```另外如果在Conda虚拟环境中，Python 3.7.6以下版本不含该动态库，可以执行命令升级Conda中Python的版本，如：`conda install python=3.7.11`。", "history": []}
{"prompt": "MindSpore有哪些现成的推荐类或生成类网络或模型可用？", "response": "目前正在开发Wide & Deep、DeepFM、NCF等推荐类模型，NLP领域已经支持Bert_NEZHA，正在开发MASS等模型，用户可根据场景需要改造为生成类网络，可以关注[MindSpore ModelZoo](https://gitee.com/mindspore/models/blob/master/README_CN.md#)。", "history": []}
{"prompt": "MindSpore并行模型训练的优势和特色有哪些？", "response": "MindSpore分布式训练除了支持数据并行，还支持算子级模型并行，可以对算子输入tensor进行切分并行。在此基础上支持自动并行，用户只需要写单卡脚本，就能自动切分到多个节点并行执行。", "history": []}
{"prompt": "最近出来的taichi编程语言有Python扩展，类似`import taichi as ti`就能直接用了，MindSpore是否也支持？", "response": "MindSpore支持Python原生表达，`import mindspore`相关包即可使用。", "history": []}
{"prompt": "模型转移时如何把PyTorch的权重加载到MindSpore中？", "response": "首先输入PyTorch的`pth`文件，以`ResNet-18`为例，MindSpore的网络结构和PyTorch保持一致，转完之后可直接加载进网络，这边参数只用到`BN`和`Conv2D`，若有其他层`ms`和PyTorch名称不一致，需要同样的修改名称。", "history": []}
{"prompt": "编译时报错“This comparator 'AnyValue' is not supported. For statement 'is'， only support compare with 'None'， 'False' or 'True'”怎么办？", "response": "对于语法`is` 或 `is not`而言，当前`MindSpore`仅支持与`True`、`False`和`None`的比较。暂不支持其他类型，如字符串等。", "history": []}
