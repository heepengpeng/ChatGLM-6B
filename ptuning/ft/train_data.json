{"prompt": "请问如果不使用高阶API，怎么实现数据下沉？", "response": "可以参考此手动下沉方式的[test_tdt_data_transfer.py](https://gitee.com/mindspore/mindspore/blob/master/tests/st/data_transfer/test_tdt_data_transfer.py)示例实现，不用借助`model.train`接口，目前支持：GPU和Ascend硬件使用。", "history": []}
{"prompt": "在使用`Dataset`处理数据过程中内存占用高，怎么优化？", "response": "可以参考如下几个步骤来降低内存占用，同时也可能会降低数据处理的效率。\t1. 在定义数据集`**Dataset`对象前，设置`Dataset`数据处理预取的大小，`ds.config.set_prefetch_size(2)`。\t\t  2. 在定义`**Dataset`对象时，设置其参数`num_parallel_workers`为1。\t\t  3. 如果对`**Dataset`对象进一步使用了`.map(...)`操作，可以设置`.map(...)`的参数`num_parallel_workers`为1。\t\t  4. 如果对`**Dataset`对象进一步使用了`.batch(...)`操作，可以设置`.batch(...)`的参数`num_parallel_workers`为1。\t\t  5. 如果对`**Dataset`对象进一步使用了`.shuffle(...)`操作，可以把参数`buffer_size`设置减少。", "history": []}
{"prompt": "在使用`Dataset`处理数据过程中CPU占用高，表现为sy占用高而us占用低，怎么优化？", "response": "可以参考如下几个步骤来降低CPU占用，进一步提升性能，其主要原因是三方库多线程与数据处理多线程存在资源竞争。\t1. 如果数据处理阶段有opencv的`cv2`操作，那么通过`cv2.setNumThreads(2)`设置`cv2`全局线程数。\t\t  2. 如果数据处理阶段有`numpy`操作，那么通过`export OPENBLAS_NUM_THREADS=1`设置`OPENBLAS`线程数。", "history": []}
{"prompt": "在`GeneratorDataset`中，看到有参数`shuffle`，在跑任务时发现`shuffle=True`和`shuffle=False`，两者没有区别，这是为什么？", "response": "开启`shuffle`，需要传入的`Dataset`是支持随机访问的（例如自定义的`Dataset`有`getitem`方法），如果是在自定义的`Dataset`里面通过`yeild`方式返回回来的数据，是不支持随机访问的，具体可查看教程中的[自定义数据集](https://www.mindspore.cn/tutorials/zh-CN/master/advanced/dataset/custom.html)章节。", "history": []}
{"prompt": "请问`Dataset`如何把两个`columns`合并成一个`column`？", "response": "可以添加如下操作把 两个字段合成一个。\t```python\tdef combine(x， y):\t    x = x.flatten()\t    y = y.flatten()\t    return np.append(x， y)\t\tdataset = dataset.map(operations=combine， input_columns=[\"data\"， \"data2\"]， output_columns=[\"data\"])\t```注：因为两个`columns`是不同的`shape`，需要先`flatten`下，然后再合并。", "history": []}
{"prompt": "请问`GeneratorDataset`支持`ds.PKSampler`采样吗？", "response": "自定义数据集`GeneratorDataset`不支持`PKSampler`采样逻辑。主要原因是自定义数据操作灵活度太大了，内置的`PKSampler`难以做到通用性，所以选择在接口层面直接提示不支持。但是对于`GeneratorDataset`，可以方便的定义自己需要的`Sampler`逻辑，即在`ImageDataset`类的`__getitem__`函数中定义具体的`sampler`规则，返回自己需要的数据即可。", "history": []}
{"prompt": "MindSpore如何加载已有的预训练词向量？", "response": "可以在定义EmbedingLookup或者Embedding时候，把预训练的词向量传进来，把预训练的词向量封装成一个Tensor作为EmbeddingLookup初始值。", "history": []}
{"prompt": "请问`c_transforms`和`py_transforms`有什么区别，比较推荐使用哪个？", "response": "推荐使用`c_transforms`，因为纯C层执行，所以性能会更好。\t原理:`c_transform`底层使用的是C版本`opencv/jpeg-turbo`进行的数据处理，`py_transform`使用的是Python版本的`Pillow`进行数据处理。", "history": []}
{"prompt": "由于我一条数据包含多个图像，并且每个图像的宽高都不一致，需要对转成mindrecord格式的数据进行`map`操作。可是我从`record`读取的数据是`np.ndarray`格式的数据，我的数据处理的`operations`是针对图像格式的。我应该怎么样才能对所生成的mindrecord的格式的数据进行预处理呢？", "response": "建议你按照如下操作进行:\t```python\t#1 The defined schema is as follows: Among them， data1， data2， data3， ... These fields store your image， and only the binary of the image is stored here.\t\tcv_schema_json = {\"label\": {\"type\": \"int32\"}， \"data1\": {\"type\": \"bytes\"}， \"data2\": {\"type\": \"bytes\"}， \"data3\": {\"type\": \"bytes\"}}\t\t#2 The organized data can be as follows， and then this data_list can be written by FileWriter.write_raw_data(...).\t\tdata_list = []\tdata = {}\tdata['label'] = 1\t\tf = open(\"1.jpg\"， \"rb\")\timage_bytes = f.read()\tf.close\t\tdata['data1'] = image_bytes\t\tf2 = open(\"2.jpg\"， \"rb\")\timage_bytes2 = f2.read()\tf2.close\t\tdata['data2'] = image_bytes2\t\tf3 = open(\"3.jpg\"， \"rb\")\timage_bytes3 = f3.read()\tf3.close\t\tdata['data3'] = image_bytes3\t\tdata_list.append(data)\t\t#3 Use MindDataset to load， then use the decode operator we provide to decode， and then perform subsequent processing.\t\tdata_set = ds.MindDataset(\"mindrecord_file_name\")\tdata_set = data_set.map(input_columns=[\"data1\"]， operations=vision.Decode()， num_parallel_workers=2)\tdata_set = data_set.map(input_columns=[\"data2\"]， operations=vision.Decode()， num_parallel_workers=2)\tdata_set = data_set.map(input_columns=[\"data3\"]， operations=vision.Decode()， num_parallel_workers=2)\tresize_op = vision.Resize((32， 32)， interpolation=Inter.LINEAR)\tdata_set = data_set.map(operations=resize_op， input_columns=[\"data1\"]， num_parallel_workers=2)\tfor item in data_set.create_dict_iterator(output_numpy=True):\t    print(item)\t```", "history": []}
{"prompt": "我的自定义图像数据集转为mindrecord格式时，我的数据是`numpy.ndarray`格式的，且`shape`为[4，100，132，3]，这个`shape`的含义是四幅三通道的帧，且每个值都在0~255。可是当我查看转化成mindrecord的格式的数据时，发现是`[19800]`的`shape`，我原数据的维度全部展开有`[158400]`，请问这是为什么？", "response": "可能是你数据中`ndarray`的`dtype`是`int8`，因为`[158400]`和`[19800]`刚好相差了8倍，建议将数据中`ndarray`的`dtype`指定为`float64`。", "history": []}
{"prompt": "想要保存生成的图片，代码运行完毕以后在相应目录找不到图片。相似的，在JupyterLab中生成数据集用于训练，训练时可以在相应路径读取到数据，但是自己却无法在路径中找到图片或数据集？", "response": "可能是JumperLab生成的图片或者数据集都是在Docker内，`moxing`下载的数据只能训练进程的Docker内看见，训练完成后这些数据就随着Docker释放了。 可以试试在训练任务中将需要`download`的数据再通过`moxing`传回`obs`，然后再在`obs`里面下载到你本地。", "history": []}
{"prompt": "MindSpore中`model.train`的`dataset_sink_mode`参数该如何理解？", "response": "当`dataset_sink_mode=True`时，数据处理会和网络计算构成Pipeline方式，即: 数据处理在逐步处理数据时，处理完一个`batch`的数据，会把数据放到一个队列里，这个队列用于缓存已经处理好的数据，然后网络计算从这个队列里面取数据用于训练，那么此时数据处理与网络计算就`Pipeline`起来了，整个训练耗时就是数据处理/网络计算耗时最长的那个。\t当`dataset_sink_mode=False`时，数据处理会和网络计算构成串行的过程，即: 数据处理在处理完一个`batch`后，把这个`batch`的数据传递给网络用于计算，在计算完成后，数据处理再处理下一个`batch`，然后把这个新的`batch`数据传递给网络用于计算，如此的循环往复，直到训练完。该方法的总耗时是数据处理的耗时+网络计算的耗时=训练总耗时。", "history": []}
{"prompt": "MindSpore能否支持按批次对不同尺寸的图片数据进行训练？", "response": "你可以参考yolov3对于此场景的使用，里面有对于图像的不同缩放，脚本见[yolo_dataset](https://gitee.com/mindspore/models/blob/master/official/cv/yolov3_darknet53/src/yolo_dataset.py)。", "history": []}
{"prompt": "使用MindSpore做分割训练，必须将数据转为MindRecord吗？", "response": "[build_seg_data.py](https://gitee.com/mindspore/models/blob/master/official/cv/deeplabv3/src/data/build_seg_data.py)是将数据集生成MindRecord的脚本，可以直接使用/适配下你的数据集。或者如果你想尝试自己实现数据集的读取，可以使用`GeneratorDataset`自定义数据集加载。\t[GenratorDataset 示例](https://www.mindspore.cn/tutorials/zh-CN/master/advanced/dataset/custom.html)\t[GenratorDataset API说明](https://www.mindspore.cn/docs/zh-CN/master/api_python/dataset/mindspore.dataset.GeneratorDataset.html#mindspore.dataset.GeneratorDataset)", "history": []}
{"prompt": "MindSpore在Ascend硬件平台进行多卡训练，自定义数据集如何给不同卡传递不同数据？", "response": "使用`GeneratorDataset`的时候，可以使用`num_shards=num_shards`，`shard_id=device_id`参数来控制不同卡读取哪个分片的数据，`__getitem__`和`__len__`按全量数据集处理即可。\t举例:\t```python\t# 卡0:\tds.GeneratorDataset(...， num_shards=8， shard_id=0， ...)\t# 卡1:\tds.GeneratorDataset(...， num_shards=8， shard_id=1， ...)\t# 卡2:\tds.GeneratorDataset(...， num_shards=8， shard_id=2， ...)\t...\t# 卡7:\tds.GeneratorDataset(...， num_shards=8， shard_id=7， ...)\t```", "history": []}
{"prompt": "如何构建图像的多标签MindRecord格式数据集？", "response": "数据Schema可以按如下方式定义: `cv_schema_json = {\"label\": {\"type\": \"int32\"， \"shape\": [-1]}， \"data\": {\"type\": \"bytes\"}}`\t说明: label是一个数组，numpy类型，这里面可以存 1， 1，0，1， 0， 1 这么多label值，这些label值对应同一个data，即: 同一个图像的二进制值。\t可以参考[将数据集转换为MindRecord](https://www.mindspore.cn/tutorials/zh-CN/master/advanced/dataset/record.html#转换成record格式)教程。", "history": []}
{"prompt": "请问自己制作的黑底白字`28*28`的数字图片，使用MindSpore训练出来的模型做预测，报错提示`wrong shape of image`是怎么回事？", "response": "首先MindSpore训练使用的灰度图MNIST数据集。所以模型使用时对数据是有要求的，需要设置为`28*28`的灰度图，就是单通道才可以。", "history": []}
{"prompt": "第一次看到有专门的数据处理框架，能介绍下么？", "response": "MindData提供数据处理异构硬件加速功能，高并发数据处理`pipeline`同时支持`Ascend/GPU/CPU`，`CPU`占用降低30%，点击查询[优化数据处理](https://www.mindspore.cn/tutorials/experts/zh-CN/master/dataset/optimize.html)。", "history": []}
{"prompt": "网络训练时出现报错提示数据下发失败“TDT Push data into device Failed”，如何定位原因？", "response": "首先上述报错指的是通过训练数据下发通道（TDT，train data transfer)发送数据到卡（device）上失败，导致这一报错的原因可能有多种，因此日志中给出了相应的检查建议，具体而言:\t1. 通常我们会找到日志中最先抛出的错误（第一个ERROR级别的错误）或报错堆栈（TraceBack)，并尝试从中找到有助于定位错误原因的信息。\t\t  2. **在图编译阶段，训练还没开始报错时**（例如日志中还没打印loss)，请先检查下报错（ERROR）日志中是否有网络中涉及的相关算子报错或涉及环境没配置好导致的报错（如hccl.json不对导致多卡通信初始化异常）。\t\t  3. **在中间训练过程中报错时**，通常为下发的数据量（batch数）与网络训练需要的数据量（step数）不匹配导致的，可以通过`get_dataset_size`接口打印一个epoch中包含的batch数，导致异常的部分可能原因如下：\t\t      - 通过查看打印loss次数的等方式判断如果数据量（step数）刚好为一个epoch中batch数的整数倍，则可能是数据处理部分涉及epoch的处理存在问题，如下面这场景:\t\t          ```python\t          ...\t          dataset = dataset.create_tuple_iteator(num_epochs=-1) # 此处如果要返回一个迭代器则num_epochs应该给1， 但建议直接返回dataset\t          return dataset\t          ```\t\t      - 考虑是否是数据处理性能较慢，跟不上网络训练的速度，针对这一场景，可借助profiler工具和MindInsight看一下是否存在明显的迭代间隙，或手动遍历一下dataset，并打印计算下平均单batch的耗时，是否比网络正反向加起来的时间更长，如果是则大概率需要对数据处理部分进行性能优化。\t\t      - 训练过程中出现异常数据抛出异常导致下发数据失败，通常这种情况会有其他报错（ERROR）日志会提示数据处理哪个环节出现了异常及检查建议。如果不明显，也可以通过遍历dataset每条数据的方式尝试找出异常的数据（如关闭shuffle， 然后进行二分法）。\t\t  4. 如果**在训练结束后**打印这条日志（大抵是强制释放资源导致），可忽略这个报错。\t\t  5. 如果仍不能定位具体原因，请通过提issue或论坛提问等方式找模块开发人员协助定位。", "history": []}
{"prompt": "py_transforms 和 c_transforms 算子能否混合使用，如果混合使用具体需要怎么使用？", "response": "出于高性能考虑，通常不建议将py_transforms 与 c_transforms算子混合使用，[文档](https://www.mindspore.cn/tutorials/zh-CN/master/advanced/dataset/enhanced_image_data.html#注意事项)也对此进行了说明。但若不追求极致的性能，主要考虑打通流程，在无法全部使用c_transforms算子（缺少对应的c_transforms算子）的情况下，可使用py_transforms算子替代，此时即存在混合使用。\t对此我们需要注意c_transforms 算子的输出通常是numpy array，py_transforms算子的输出是PIL Image，具体可查看算子说明，为此通常的混合使用方法为：\t- c_transforms 算子 + ToPIL 算子 + py_transforms 算子 + ToTensor算子\t- py_transforms 算子 + ToTensor 算子 + c_transforms 算子\t```python\t# example that using c_transforms and py_transforms operators together\t# in following case: c_vision refers to c_transforms， py_vision refer to py_transforms\t\tdecode_op = c_vision.Decode()\t\t# If input type is not PIL， then add ToPIL operator.\ttransforms = [\t    py_vision.ToPIL()，\t    py_vision.CenterCrop(375)，\t    py_vision.ToTensor()\t]\ttransform = mindspore.dataset.transforms.py_transforms.Compose(transforms)\tdata1 = data1.map(operations=decode_op， input_columns=[\"image\"])\tdata1 = data1.map(operations=transform， input_columns=[\"image\"])\t```", "history": []}
{"prompt": "当错误提示 \"The data pipeline is not a tree (i.e.， one node has 2 consumers)\" 应该怎么检查？", "response": "上述错误通常是脚本书写错误导致，具体发生在下面这种场景；正常情况下数据处理pipeline中的操作是依次串联的，下面的异常场景中dataset1有两个消费节点 dataset2和dataset3，就会出现上述错误。\t```python\t dataset2 = dataset1.map(***)\t dataset3 = dataset1.map(***)\t```正确的写法如下所示，dataset3是由dataset2进性数据增强得到的，而不是在dataset1基础上进行数据增强操作得到。\t```python\t dataset2 = dataset1.map(***)\t dataset3 = dataset2.map(***)\t```", "history": []}
{"prompt": "MindSpore中和Dataloader对应的算子是什么？", "response": "如果将Dataloader考虑为接收自定义Dataset的API接口，MindSpore数据处理API中和Dataloader较为相似的是GeneratorDataset，可接收用户自定义的Dataset，具体使用方式参考[GeneratorDataset 文档](https://www.mindspore.cn/tutorials/zh-CN/master/advanced/dataset/custom.html)，差异对比也可查看[API算子映射表](https://www.mindspore.cn/docs/zh-CN/master/note/api_mapping/pytorch_api_mapping.html)。", "history": []}
{"prompt": "自定义的Dataset出现错误时，应该如何调试？", "response": "自定义的Dataset通常会传入到GeneratorDataset，在使用过程中错误指向了自定义的Dataset时，可通过一些方式进行调试（如增加打印信息，打印返回值的shape、dtype等），自定义Dataset通常要保持中间处理结果为numpy array，且不建议与MindSpore网络计算的算子混合使用。此外针对自定义的Dataset如下面的MyDataset，初始化后也可直接进行如下遍历（主要为简化调试，分析原始Dataset中的问题，可不传入GeneratorDataset)，调试遵循常规的Python语法规则。\t```python\tDataset = MyDataset()\tfor item in Dataset:\t   print(\"item:\"， item)\t```", "history": []}
{"prompt": "数据处理算子与网络计算算子能否混合使用？", "response": "通常数据处理算子与网络计算算子混合使用会导致性能有所降低，在缺少对应的数据处理算子且自定义py_transforms算子不合适时可进行尝试。需要注意的是，因为二者需要的输入不一致，数据处理算子通常输入为numpy array 或 PIL Image，但网络计算算子输入需要是MindSpore.Tensor;\t将二者混合使用需要使上一个算子的输出格式和下一个算子所需的输入格式一致。数据处理算子指的是官网API文档中mindspore.dataset开头的算子，如 mindspore.dataset.vision.c_transforms.CenterCrop，网络计算算子包含 mindspore.nn、 mindspore.ops等目录下的算子。", "history": []}
{"prompt": "MindRecord为何会生成.db文件？ 缺少.db文件时加载数据集会有什么报错？", "response": ".db文件为MindRecord文件对应的索引文件，缺少.db文件通常会在获取数据集总的数据量时报错，错误提示如：`MindRecordOp Count total rows failed`。", "history": []}
{"prompt": "自定义Dataset中如何进行图像读取并进行Decode操作？", "response": "传入GeneratorDataset的自定义Dataset，在接口内部（如`__getitem__`函数）进行图像读取后可以直接返回bytes类型的数据、numpy array类型的数组或已经做了解码操作的numpy array， 具体如下所示：\t- 读取图像后直接返回bytes类型的数据\t\t    ```python\t    class ImageDataset:\t        def __init__(self， data_path):\t            self.data = data_path\t\t        def __getitem__(self， index):\t            # use file open and read method\t            f = open(self.data[index]， 'rb')\t            img_bytes = f.read()\t            f.close()\t\t            # return bytes directly\t            return (img_bytes， )\t\t        def __len__(self):\t            return len(self.data)\t\t    # data_path is a list of image file name\t    dataset1 = ds.GeneratorDataset(ImageDataset(data_path)， [\"data\"])\t    decode_op = py_vision.Decode()\t    to_tensor = py_vision.ToTensor(output_type=np.int32)\t    dataset1 = dataset1.map(operations=[decode_op， to_tensor]， input_columns=[\"data\"])\t    ```\t\t- 读取图像后返回numpy array\t\t    ```python\t    # 在上面的用例中，对__getitem__函数可进行如下修改， Decode操作同上述用例一致\t    def __getitem__(self， index):\t        # use np.fromfile to read image\t        img_np = np.fromfile(self.data[index])\t\t        # return Numpy array directly\t        return (img_np， )\t    ```\t\t- 读取图像后直接进行Decode操作\t\t    ```python\t    # 依据上面的用例，对__getitem__函数可进行如下修改， 直接返回Decode之后的数据，此后可以不需要通过map算子接Decode操作\t    def __getitem__(self， index):\t        # use Image.Open to open file， and convert to RGC\t        img_rgb = Image.Open(self.data[index]).convert(\"RGB\")\t        return (img_rgb， )\t    ```", "history": []}
{"prompt": "在使用`Dataset`处理数据过程中，报错`RuntimeError: can't start new thread`，怎么解决？", "response": "主要原因是在使用`**Dataset`、`.map(...)`和`.batch(...)`时，参数`num_parallel_workers`配置过大，用户进程数达到最大，可以通过`ulimit -u 最大进程数`来增加用户最大进程数范围，或者将`num_parallel_workers`配置减小。", "history": []}
{"prompt": "在使用`GeneratorDataset`加载数据时，报错`RuntimeError: Failed to copy data into tensor.`，怎么解决？", "response": "在使用`GeneratorDataset`加载Pyfunc返回的Numpy array时，MindSpore框架将执行Numpy array到MindSpre Tensor的转换，假设Numpy array所指向的内存被释放，可能会发生内存拷贝的错误。举例如下：\t- 在`__getitem__`函数中执行Numpy array - MindSpore Tensor - Numpy array的就地转换。其中Tensor `tensor`和Numpy array `ndarray_1`共享同一块内存，Tensor `tensor`在`__getitem__`函数退出时超出作用域，其所指向的内存将被释放。\t\t    ```python\t    class RandomAccessDataset:\t        def __init__(self):\t            pass\t\t        def __getitem__(self， item):\t            ndarray = np.zeros((544， 1056， 3))\t            tensor = Tensor.from_numpy(ndarray)\t            ndarray_1 = tensor.asnumpy()\t            return ndarray_1\t\t        def __len__(self):\t            return 8\t\t    data1 = ds.GeneratorDataset(RandomAccessDataset()， [\"data\"])\t    ```\t\t- 忽略上面例子中的循环转换，在`__getitem__`函数退出时，Tensor对象`tensor`被释放，和其共享同一块内存的Numpy array对象`ndarray_1`变成未知状态，为了规避此问题可以直接使用`deepcopy`函数为将返回的Numpy array对象`ndarray_2`申请独立的内存。\t\t    ```python\t    class RandomAccessDataset:\t        def __init__(self):\t            pass\t\t        def __getitem__(self， item):\t            ndarray = np.zeros((544， 1056， 3))\t            tensor = Tensor.from_numpy(ndarray)\t            ndarray_1 = tensor.asnumpy()\t            ndarray_2 = copy.deepcopy(ndarray_1)\t            return ndarray_2\t\t        def __len__(self):\t            return 8\t\t    data1 = ds.GeneratorDataset(RandomAccessDataset()， [\"data\"])\t    ```", "history": []}
{"prompt": "进行HCCL分布式训练出错：`Init plugin so failed， ret = 1343225860`？", "response": "初始化HCCL失败了，通常由于`rank json`没写对，可以用`mindspore/model_zoo/utils/hccl_tools`下面的工具生成一个试试。或者导入环境变量`export ASCEND_SLOG_PRINT_TO_STDOUT=1`打开HCCL的日志打印，然后检查日志信息。", "history": []}
{"prompt": "MindSpore执行GPU分布式训练报错如下，如何解决:", "response": "```text\tLoading libgpu_collective.so failed. Many reasons could cause this:\t1.libgpu_collective.so is not installed.\t2.nccl is not installed or found.\t3.mpi is not installed or found\t```此问题为MindSpore动态加载集合通信库失败，可能原因如下:\t- 执行环境未安装分布式训练依赖的OpenMPI以及NCCL。\t- NCCL版本未更新至`v2.7.6`: MindSpore `v1.1.0`新增GPU P2P通信算子，该特性依赖于NCCL `v2.7.6`，若环境使用的NCCL未升级为此版本，则会引起加载失败错误。", "history": []}
{"prompt": "GPU分布式训练场景下，若错误设置环境变量CUDA_VISIBLE_DEVICES的个数小于执行的进程数时，可能导致进程阻塞问题。", "response": "此场景下，部分训练进程会提示如下报错：\t```text\t[ERROR] DEVICE [mindspore/ccsrc/runtime/device/gpu/cuda_driver.cc:245] SetDevice] SetDevice for id:7 failed， ret[101]， invalid device ordinal. Please make sure that the 'device_id' set in context is in the range:[0， total number of GPU). If the environment variable 'CUDA_VISIBLE_DEVICES' is set， the total number of GPU will be the number set in the environment variable 'CUDA_VISIBLE_DEVICES'. For example， if export CUDA_VISIBLE_DEVICES=4，5，6， the 'device_id' can be 0，1，2 at the moment， 'device_id' starts from 0， and 'device_id'=0 means using GPU of number 4.\t[ERROR] DEVICE [mindspore/ccsrc/runtime/device/gpu/gpu_device_manager.cc:27] InitDevice] Op Error: Failed to set current device id | Error Number: 0\t```其余进程由于GPU资源已分配成功，会正常执行到初始化`NCCL`步骤，日志如下：\t```text\t[INFO] DEVICE [mindspore/ccsrc/runtime/hardware/gpu/gpu_device_context.cc:90] Initialize] Start initializing NCCL communicator for device 1\t```此步骤中会调用`NCCL`接口`ncclCommInitRank`，该接口会阻塞，直到所有进程达成一致。因此如果某进程没有调用`ncclCommInitRank`，则会导致进程阻塞。\t此问题我们已向`NCCL`社区反馈，社区开发者正在设计解决方案中，目前最新版本还未修复，详见[issue链接](https://github.com/NVIDIA/nccl/issues/593#issuecomment-965939279)。\t解决方法：手动`kill`训练进程，根据报错日志，设置正确的卡号后，重启训练任务。", "history": []}
{"prompt": "GPU分布式训练场景下，若某进程异常退出，可能导致其余进程阻塞问题。", "response": "此场景下，异常进程由于各种问题退出，其余进程由于GPU资源已分配成功，会正常执行到初始化`NCCL`步骤，日志如下：\t```text\t[INFO] DEVICE [mindspore/ccsrc/runtime/hardware/gpu/gpu_device_context.cc:90] Initialize] Start initializing NCCL communicator for device 1\t```此步骤中会调用`NCCL`接口`ncclCommInitRank`，该接口会阻塞，直到所有进程达成一致。因此如果某进程没有调用`ncclCommInitRank`，则会导致进程阻塞。\t此问题我们已向`NCCL`社区反馈，社区开发者正在设计解决方案中，目前最新版本还未修复，详见[issue链接](https://github.com/NVIDIA/nccl/issues/593#issuecomment-965939279)。\t解决方法：手动`kill`训练进程后重启训练任务。", "history": []}
{"prompt": "在执行GPU单机单卡的脚本时，不使用mpirun启动进程时，调用mindspore.communication.init方法可能会报错，导致执行失败，该如何处理？", "response": "```text\t[CRITICAL] DISTRIBUTED [mindspore/ccsrc/distributed/cluster/cluster_context.cc:130] InitNodeRole] Role name is invalid...\t```在用户不使用`mpirun`启动进程，但是依然调用了`init()`方法的情况下，MindSpore要求用户按照[不依赖OpenMPI进行训练](https://www.mindspore.cn/tutorials/experts/zh-CN/master/parallel/train_gpu.html#不依赖openmpi进行训练)配置若干环境变量并进行校验，若没有配置，MindSpore会给出以上报错提示。因此建议只有在执行分布式训练时调用`mindspore.communication.init`，并在不使用`mpirun`的场景下，根据文档配置正确的环境变量以启动分布式训练。", "history": []}
{"prompt": "在通过OpenMPI执行多机多卡训练时，提示由于MPI_Allgather失败。", "response": "```text\tpml_ucx.c:175 Error: Failed to receive UCX worker address: Not found (-13)\tpml_ucx.c:452 Error: Failed to resolve UCX endpoint for rank X\t```此问题是`OpenMPI`在Host侧通信时，无法和对端地址进行通信，一般是机器之间的网卡配置不同导致的，可以通过手动设置网卡名或者子网的方式解决：\t```text\tmpirun -n process_num --mca btl tcp --mca btl_tcp_if_include eth0 ./run.sh\t```以上指令启动了`process_num`个`run.sh`进程，并且选择Host侧通信方式为`tcp`，网卡选择了`eth0`，这样就能保证在每台机器上使用的网卡相同，进而解决通信异常问题。\t还可以选择子网来进行匹配：\t```text\tmpirun -n process_num --mca btl tcp --mca btl_tcp_if_include 192.168.1.0/24 ./run.sh\t```子网范围需要包括所有机器所用的IP地址。", "history": []}
{"prompt": "在通过OpenMPI执行分布式训练时，单机多卡训练正常，但在多机多卡训练时，某些机器提示GPU device id设置失败。", "response": "```text\t[ERROR] DEVICE [mindspore/ccsrc/runtime/device/gpu/cuda_driver.cc:245] SetDevice] SetDevice for id:7 failed， ret[101]， invalid device ordinal. Please make sure that the 'device_id' set in context is in the range:[0， total number of GPU). If the environment variable 'CUDA_VISIBLE_DEVICES' is set， the total number of GPU will be the number set in the environment variable 'CUDA_VISIBLE_DEVICES'. For example， if export CUDA_VISIBLE_DEVICES=4，5，6， the 'device_id' can be 0，1，2 at the moment， 'device_id' starts from 0， and 'device_id'=0 means using GPU of number 4.\t[ERROR] DEVICE [mindspore/ccsrc/runtime/device/gpu/gpu_device_manager.cc:27] InitDevice] Op Error: Failed to set current device id | Error Number: 0\t```在多机场景下，各进程卡号需要通过在Host侧`AllGather` `HOSTNAME`后计算得到，如果机器间有使用相同的`HOSTNAME`，则进程卡号会计算出错，导致卡号越界而设置失败。可以在执行脚本中设置每台机器的HOSTNAME为各自的IP地址来解决：\t```text\texport HOSTNAME=node_ip_address\t```", "history": []}
{"prompt": "在通过OpenMPI执行多机多卡训练时，NCCL报错提示网络不通。", "response": "```text\tinclude/socket.h:403 NCCL WARN Connect to XXX failed: Network is unreachable\t```此问题是`NCCL`在Host侧同步进程信息或者初始化通信域时，无法和对端地址进行通信，一般是机器之间的网卡配置不同导致的，可以通过设置`NCCL`环境变量`NCCL_SOCKET_IFNAME`，进行网卡选择：\t```text\texport NCCL_SOCKET_IFNAME=eth\t```以上指令设置了`NCCL`在Host侧选择网卡名中带有`eth`的网卡进行通信。", "history": []}
{"prompt": "多机多卡选择特定名称的RDMA网卡(通过NCCL_SOCKET_IFNAME设置)通信后，训练仍然报错：", "response": "```text\tmisc/ibvwrap.cc:284 NCCL WARN Call to ibv_modify_qp failed with error Invalid argument\t...\tinclude/socket.h:403 NCCL WARN Connect to XXX failed: Connection refused\t```一般此问题是多机之间RDMA网卡配置存在差异，需要具体情况具体分析。但常见原因是存在某些主机网卡存在IB协议和RoCE协议同时存在的情况，可能出现连接建立失败的情况。解决方案：\t需要使用以下指令指定使用的RDMA网卡名为ib开头：\t```text\texport NCCL_IB_HCA=ib\t```", "history": []}
{"prompt": "单机多卡训练能够成功，但是扩展脚本到多机多卡后，其他主机提示各类报错：", "response": "报错内容有多种，下面是几种典型的报错，可能有：\t1.已经安装的whl包找不到。\t2.IB网卡通信失败。\t3.Cuda库加载失败。\t这些问题，都是由于在`mpirun`启动其他主机时，其他主机的环境变量(包括NCCL的网卡选择配置)没有与本机同步，导致了单机多卡正常执行而多机多卡失败的现象。解决方法是通过mpirun的-x选项，导出特定的环境变量：\t```text\tmpirun --hostfile /path/to/hostfile -n 64 -x PYTHONPATH -x GLOG_v -x LD_LIBRARY_PATH -x NCCL_SOCKET_IFNAME -x NCCL_IB_HCA -x NCCL_DEBUG=INFO python train.py\t```以上指令导出了在本机已经设置的一些环境变量到其他主机，保证了在执行训练脚本前所有主机环境变量保持一致，达到多机多卡训练目标。", "history": []}
{"prompt": "导出MindIR格式的时候，`input=np.random.uniform(...)`是不是固定格式？", "response": "不是固定格式的，这一步操作是为了创建一个输入，以便于构建网络结构。`export`里只要传入正确的`shape`即可，使用`np.ones`和`np.zeros`创建都是可以的。", "history": []}
{"prompt": "MindSpore现支持直接读取哪些其他框架的模型和哪些格式呢？比如PyTorch下训练得到的pth模型可以加载到MindSpore框架下使用吗？", "response": " MindSpore采用Protobuf存储训练参数，无法直接读取其他框架的模型。对于模型文件本质保存的就是参数和对应的值，可以用其他框架的API将参数读取出来之后，拿到参数的键值对，然后再加载到MindSpore中使用。比如想用其他框架训练好的ckpt文件，可以先把参数读取出来，再调用MindSpore的`save_checkpoint`接口，就可以保存成MindSpore可以读取的ckpt文件格式了。", "history": []}
{"prompt": "在使用ckpt或导出模型的过程中，报Protobuf内存限制错误，如何处理？", "response": "当单条Protobuf数据过大时，因为Protobuf自身对数据流大小的限制，会报出内存限制的错误。这时可通过设置环境变量`PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python`解除限制。", "history": []}
{"prompt": "PyNative模式和Graph模式的区别？", "response": "通过下面四个方面进行对比：\t- 网络执行：两个模式使用的算子是一致的，因此相同的网络和算子，分别在两个模式下执行时，精度效果是一致的。由于Graph模式运用了图优化、计算图整图下沉等技术，Graph模式执行网络的性能和效率更高；\t\t- 场景使用：Graph模式需要一开始就构建好网络结构，然后框架做整图优化和执行，比较适合网络固定没有变化，且需要高性能的场景；\t\t- 不同硬件（`Ascend`、`GPU`和`CPU`）资源：都支持这两种模式；\t\t- 代码调试：由于PyNative模式是逐行执行算子，用户可以直接调试Python代码，在代码中任意位置打断点查看对应算子的输出或执行结果。而Graph模式由于在构造函数里只是完成网络构造，实际没有执行，因此在`construct`函数里打断点无法获取对应算子的输出，只能先指定算子进行打印，然后在网络执行完成后查看输出结果。", "history": []}
{"prompt": "使用MindSpore在GPU上训练的网络脚本可以不做修改直接在Ascend上进行训练么？", "response": "可以的，MindSpore面向Ascend/GPU/CPU提供统一的API，在算子支持的前提下，网络脚本可以不做修改直接跨平台运行。", "history": []}
{"prompt": "一个环境中如果既安装了MindSpore，又安装了PyTorch，是否在一个python文件中可以混用两个框架的语法呢？", "response": "可以在一个python文件中混用两个框架的。要注意类型间的区别。例如两个框架创建的Tensor类型是不同的，但对于python的基础类型都是通用的。", "history": []}
{"prompt": "MindSpore可以读取TensorFlow的ckpt文件吗？", "response": "MindSpore的`ckpt`和TensorFlow的`ckpt`格式是不通用的，虽然都是使用`Protobuf`协议，但是`proto`的定义是不同的。当前MindSpore不支持读取TensorFlow或PyTorch的`ckpt`文件。", "history": []}
{"prompt": "用MindSpore训练出的模型如何在Ascend 310上使用？可以转换成适用于HiLens Kit用的吗？", "response": "Ascend 310需要运行专用的OM模型，先使用MindSpore导出ONNX或AIR模型，再转化为Ascend 310支持的OM模型。具体可参考[多平台推理](https://www.mindspore.cn/tutorials/experts/zh-CN/master/infer/ascend_310_mindir.html)。可以，HiLens Kit是以Ascend 310为推理核心，所以前后两个问题本质上是一样的，需要转换为OM模型.", "history": []}
{"prompt": "<font size=3>**Q:MindSpore只能在华为自己的`Ascend`上跑么？", "response": "MindSpore同时支持华为自己的`Ascend`、`GPU`与`CPU`，是支持异构算力的。", "history": []}
{"prompt": "MindSpore在Ascend 310上是否可以转AIR模型？", "response": "Ascend 310不能导出AIR，需要在Ascend 910加载训练好的checkpoint后，导出AIR，然后在Ascend 310转成OM模型进行推理。Ascend 910的安装方法可以参考官网MindSpore[安装指南](https://www.mindspore.cn/install)。", "history": []}
{"prompt": "MindSpore对导出、导入模型的单个Tensor输入大小有什么限制？", "response": "由于Protobuf的硬件限制，导出AIR、ONNX格式时，模型参数大小不能超过2G；导出MINDIR格式时，模型参数大小没有限制，MindSpore不支持导入AIR、ONNX格式，只支持MINDIR，导入大小的限制与导出一致。", "history": []}
{"prompt": "安装运行MindSpore时，是否要求平台有GPU计算单元？需要什么硬件支持？", "response": "MindSpore当前支持CPU/GPU/Ascend。目前笔记本电脑或者有GPU的环境，都可以通过Docker镜像来使用。当前MindSpore Model Zoo中有部分模型已经支持GPU的训练和推理，其他模型也在不断地进行完善。在分布式并行训练方面，MindSpore当前支持GPU多卡训练。你可以通过项目[Release note](https://gitee.com/mindspore/mindspore/blob/master/RELEASE.md#)获取最新信息。", "history": []}
{"prompt": "针对异构计算单元的支持，MindSpore有什么计划？", "response": "MindSpore提供了可插拔式的设备管理接口，其他计算单元（比如FPGA）可快速灵活地实现与MindSpore的对接，欢迎您参与社区进行异构计算后端的开发工作。", "history": []}
{"prompt": "MindSpore与ModelArts是什么关系，在ModelArts中能使用MindSpore吗？", "response": "ModelArts是华为公有云线上训练及推理平台，MindSpore是华为深度学习框架。", "history": []}
{"prompt": "最近出来的taichi编程语言有Python扩展，类似`import taichi as ti`就能直接用了，MindSpore是否也支持？", "response": "MindSpore支持Python原生表达，`import mindspore`相关包即可使用。", "history": []}
{"prompt": "请问MindSpore支持梯度截断吗？", "response": "支持，可以参考[梯度截断的定义和使用](https://gitee.com/mindspore/models/blob/master/official/nlp/transformer/src/transformer_for_train.py#L35)。", "history": []}
{"prompt": "MindSpore的IR设计理念是什么？", "response": "函数式: 一切皆函数，易于微分实现；无副作用，易于实现自动并行化分析。`JIT`编译能力: 图形IR，控制流依赖和数据流合一，平衡通用性/易用性。图形完备的IR: 更多的转换`Python`灵活语法，包括递归等。", "history": []}
{"prompt": "MindSpore并行模型训练的优势和特色有哪些？", "response": "MindSpore分布式训练除了支持数据并行，还支持算子级模型并行，可以对算子输入tensor进行切分并行。在此基础上支持自动并行，用户只需要写单卡脚本，就能自动切分到多个节点并行执行。", "history": []}
{"prompt": "MindSpore在语义协同和处理上是如何实现的？是否利用当前学术界流行的FCA理论？", "response": "MindSpore框架本身并不需要支持FCA。对于语义类模型，用户可以调用第三方的工具在数据预处理阶段做FCA数学分析。MindSpore本身支持Python语言，`import FCA`相关包即可使用。", "history": []}
{"prompt": "当前在云上MindSpore的训练和推理功能是比较完备的，至于边端场景（尤其是终端设备）MindSpore有什么计划？", "response": "MindSpore是端边云统一的训练和推理框架，支持将云侧训练的模型导出到Ascend AI处理器和终端设备进行推理。当前推理阶段支持的优化包括量化、算子融合、内存复用等。", "history": []}
{"prompt": "MindSpore自动并行支持情况如何？", "response": "自动并行特性对CPU GPU的支持还在完善中。推荐用户在Ascend 910 AI处理器上使用自动并行，可以关注开源社区，申请MindSpore开发者体验环境进行试用。", "history": []}
{"prompt": "MindSpore有没有类似基于TensorFlow实现的对象检测算法的模块？", "response": "TensorFlow的对象检测Pipeline接口属于TensorFlow Model模块。待MindSpore检测类模型完备后，会提供类似的Pipeline接口。", "history": []}
{"prompt": "使用PyNative模式能够进行迁移学习？", "response": "PyNative模式是兼容迁移学习的。", "history": []}
{"prompt": "MindSpore仓库中的[ModelZoo](https://gitee.com/mindspore/models/blob/master/README_CN.md#)和昇腾官网的[ModelZoo](https://www.hiascend.com/software/modelzoo)有什么关系？", "response": "MindSpore的ModelZoo主要提供MindSpore框架实现的模型，同时包括了Ascend/GPU/CPU/Mobile多种设备的支持。昇腾的ModelZoo主要提供运行于Ascend加速芯片上的模型，包括了MindSpore/PyTorch/TensorFlow/Caffe等多种框架的支持。可以参考对应的[Gitee仓库](https://gitee.com/ascend/modelzoo)\t其中MindSpore+Ascend的组合是有重合的，这部分模型会以MindSpore的ModelZoo为主要版本，定期向昇腾ModelZoo发布。", "history": []}
{"prompt": "Ascend与NPU是什么关系？", "response": "NPU指针对神经网络算法的专用处理器，不同公司推出的NPU架构各异，Ascend是基于华为公司自研的达芬奇架构的NPU。", "history": []}
{"prompt": "请问使用MindSpore如何实现多尺度训练？", "response": "在多尺度训练过程中，使用不同`shape`调用`Cell`对象的时候，会自动根据不同`shape`编译并调用不同的图，从而实现多尺度的训练。要注意多尺度训练只支持非数据下沉模式，不能支持数据下沉的训练方式。可以参考[yolov3](https://gitee.com/mindspore/models/tree/master/official/cv/yolov3_darknet53)的多尺度训练实现。", "history": []}
{"prompt": "如果MindSpore的`requires_grad=False`的`tensor`转化为`numpy`类型进行处理然后再转化会`tensor`，会对计算图和反向传播有影响吗？", "response": "在PyNative模式下，如果中间使用`numpy`计算，会导致梯度传递中断，`requires_grad=False`的场景下，如果该`tensor`的反向传播不传给其他参数使用，是没有影响的；如果`requires_grad=True`的场景下，是有影响的。", "history": []}
{"prompt": "请问怎样实现类似`torch.nn.functional.linear()`那样能够对全连接层`weight`、`bias`进行修改，应该如何操作？", "response": "MindSpore与`torch.nn.functional.linear()`功能最接近的接口就是`nn.Dense`了。`nn.Dense`能指定`weight`和`bias`的初始值，后续的变化是由优化器自动更新的。训练过程中，用户不需要主动修改这两个参数的值。", "history": []}
{"prompt": "使用MindSpore在模型保存后生成的`.meta`文件作用是什么，可以用`.meta`文件导入图结构吗？", "response": "这里的`.meta`文件是编译好的图结构，但是目前并不支持直接导入这种结构。如果不知道图结构的情况下想要导入网络，还是需要用MindIR格式的文件。", "history": []}
{"prompt": "请问`yolov4-tiny-3l.weights`模型文件可以直接转换成MindSpore模型吗？", "response": "不能的，需要把其他框架训练好的参数转换成MindSpore的格式，才能转成MindSpore的模型。", "history": []}
{"prompt": "使用MindSpore进行`model.train`的时候进行了如下设置，为什么会报错呢？", "response": "```python\tmodel.train(1， dataset， callbacks=LossMonitor(1)， dataset_sink_mode=True)\tmodel.train(1， dataset， callbacks=LossMonitor(1)， dataset_sink_mode=False)\t```因为在已经设置为下沉模式的情况下，就不能再设置为非下沉了，是运行机制上的限制。", "history": []}
{"prompt": "使用MindSpore训练模型在`eval`阶段，需要注意什么？能够直接加载网络和参数吗？需要在Model中使用优化器吗？", "response": "在`eval`阶段主要看需要什么，比如图像分类任务`eval`网络的输出是各个类的概率值，与对应标签计算`acc`。\t大多数情况是可以直接复用训练的网络和参数的，需要注意的是需要设置推理模式。\t```python\tnet.set_train(False)\t```在eval阶段不需要优化器，但是需要使用MindSpore的`model.eval`接口的话需要配置一下`loss function`，如：\t```python\t# 定义模型\tmodel = Model(net， loss_fn=loss， metrics={'top_1_accuracy'， 'top_5_accuracy'})\t# 评估模型\tres = model.eval(dataset)\t```", "history": []}
{"prompt": "如何使用SGD里的`param_group`来实现学习率的衰减？", "response": "如果需要按照`epoch`来变化，可以使用[Dynamic LR](https://mindspore.cn/docs/zh-CN/master/api_python/mindspore.nn.html#dynamic-lr函数)，把其中的`step_per_epoch`设置成`step_size`，如果需要按照`step`来变化，可以把其中的`step_per_epoch`设置成1，也可以用[LearningRateSchedule](https://mindspore.cn/docs/zh-CN/master/api_python/mindspore.nn.html#learningrateschedule)。", "history": []}
{"prompt": "MindSpore如何进行参数（如dropout值）修改？", "response": "在构造网络的时候可以通过 `if self.training: x = dropput(x)`，推理时，执行前设置`network.set_train(mode_false)`，就可以不使用dropout，训练时设置为True就可以使用dropout。", "history": []}
{"prompt": "如何查看模型参数量？", "response": "可以直接加载CheckPoint统计，可能额外统计了动量和optimizer中的变量，需要过滤下相关变量。\t您可以参考如下接口统计网络参数量:\t```python\tdef count_params(net):\t    \"\"\"Count number of parameters in the network\t    Args:\t        net (mindspore.nn.Cell): Mindspore network instance\t    Returns:\t        total_params (int): Total number of trainable params\t    \"\"\"\t    total_params = 0\t    for param in net.trainable_params():\t        total_params += np.prod(param.shape)\t    return total_params\t```具体[脚本链接](https://gitee.com/mindspore/models/blob/master/research/cv/tinynet/src/utils.py)。", "history": []}
{"prompt": "如何在训练过程中监控`loss`在最低的时候并保存训练参数？", "response": "可以自定义一个`Callback`。参考`ModelCheckpoint`的写法，此外再增加判断`loss`的逻辑:\t```python\tclass EarlyStop(Callback):\t    def __init__(self):\t        self.loss = None\t    def step_end(self， run_context):\t        loss =  ****(get current loss)\t        if (self.loss == None or loss < self.loss):\t            self.loss = loss\t            # do save ckpt\t```", "history": []}
{"prompt": "使用`nn.Conv2d`时，怎样获取期望大小的`feature map`？", "response": "`Conv2d shape`推导方法可以[参考这里](https://www.mindspore.cn/docs/zh-CN/master/api_python/nn/mindspore.nn.Conv2d.html#mindspore.nn.Conv2d)，`Conv2d`的`pad_mode`改成`same`，或者可以根据`Conv2d shape`推导公式自行计算`pad`，想要使得`shape`不变，一般pad为`(kernel_size-1)//2`。", "history": []}
{"prompt": "使用MindSpore可以自定义一个可以返回多个值的loss函数？", "response": "自定义`loss function`后还需自定义`TrainOneStepCell`，实现梯度计算时`sens`的个数和`network`的输出个数相同。具体可参考:\t```python\tnet = Net()\tloss_fn = MyLoss()\tloss_with_net = MyWithLossCell(net， loss_fn)\ttrain_net = MyTrainOneStepCell(loss_with_net， optim)\tmodel = Model(net=train_net， loss_fn=None， optimizer=None)\t```", "history": []}
{"prompt": "MindSpore如何实现早停功能？", "response": "可以自定义`callback`方法实现早停功能。\t例子: 当loss降到一定数值后，停止训练。\t```python\tclass EarlyStop(Callback):\t    def __init__(self， control_loss=1):\t        super(EarlyStop， self).__init__()\t        self._control_loss = control_loss\t\t    def step_end(self， run_context):\t        cb_params = run_context.original_args()\t        loss = cb_params.net_outputs\t        if loss.asnumpy() < self._control_loss:\t            # Stop training\t            run_context._stop_requested = True\t\tstop_cb = EarlyStop(control_loss=1)\tmodel.train(epoch_size， ds_train， callbacks=[stop_cb])\t```", "history": []}
{"prompt": "模型已经训练好，如何将模型的输出结果保存为文本或者`npy`的格式？", "response": "您好，我们网络的输出为`Tensor`，需要使用`asnumpy()`方法将`Tensor`转换为`numpy`，再进行下一步保存。具体可参考:\t```python\tout = net(x)\tnp.save(\"output.npy\"， out.asnumpy())\t```", "history": []}
{"prompt": "缓存服务器异常关闭如何处理？", "response": "缓存服务器使用过程中，会进行IPC共享内存和socket文件等系统资源的分配。若允许溢出，在磁盘空间还会存在溢出的数据文件。一般情况下，如果通过`cache_admin --stop`命令正常关闭服务器，这些资源将会被自动清理。\t但如果缓存服务器被异常关闭，例如缓存服务进程被杀等，用户需要首先尝试重新启动服务器，若启动失败，则应该依照以下步骤手动清理系统资源:\t- 删除IPC资源。\t\t    1. 检查是否有IPC共享内存残留。\t\t        一般情况下，系统会为缓存服务分配4GB的共享内存。通过以下命令可以查看系统中的共享内存块使用情况。\t\t        ```text\t        $ ipcs -m\t        ------ Shared Memory Segments --------\t        key        shmid      owner      perms      bytes      nattch     status\t        0x61020024 15532037   root       666        4294967296 1\t        ```\t\t        其中，`shmid`为共享内存块id，`bytes`为共享内存块的大小，`nattch`为链接到该共享内存块的进程数量。`nattch`不为0表示仍有进程使用该共享内存块。在删除共享内存前，需要停止使用该内存块的所有进程。\t\t    2. 删除IPC共享内存。\t\t        找到对应的共享内存id，并通过以下命令删除。\t\t        ```text\t        ipcrm -m {shmid}\t        ```\t\t- 删除socket文件。\t\t    一般情况下，socket文件位于`/tmp/mindspore/cache`。进入文件夹，执行以下命令删除socket文件。\t\t    ```text\t    rm cache_server_p{port_number}\t    ```\t\t    其中`port_number`为用户创建缓存服务器时指定的端口号，默认为50052。\t\t- 删除溢出到磁盘空间的数据文件。\t\t    进入启用缓存服务器时指定的溢出数据路径。通常，默认溢出路径为`/tmp/mindspore/cache`。找到路径下对应的数据文件夹并逐一删除。", "history": []}
{"prompt": "通过Hub可以使用GPU加载`vgg16`模型以及是否可以做迁移模型吗？", "response": "请手动修改如下两处参数即可:\t```python\t# 增加**kwargs参数: 如下\tdef vgg16(num_classes=1000， args=None， phase=\"train\"， **kwargs):\t``````python\t# 增加**kwargs参数: 如下\tnet = Vgg(cfg['16']， num_classes=num_classes， args=args， batch_norm=args.batch_norm， phase=phase， **kwargs)\t```", "history": []}
{"prompt": "如何得到VGG模型中间层特征？", "response": "你好，获取网络中间层的特征，其实跟具体框架没有太大关系了。`torchvison`里定义的`vgg`模型，可以通过`features`字段获取\"中间层特征\"，`torchvison`的`vgg`源码如下:\t```python\tclass VGG(nn.Module):\t\t    def __init__(self， features， num_classes=1000， init_weights=True):\t        super(VGG， self).__init__()\t        self.features = features\t        self.avgpool = nn.AdaptiveAvgPool2d((7， 7))\t```在MindSpore的ModelZoo里定义的`vgg16`，可以通过`layers`字段获取，如下:\t```python\tnetwork = vgg16()\tprint(network.layers)\t```", "history": []}
{"prompt": "使用MindSpore进行模型训练时，`CTCLoss`的输入参数有四个: `inputs`， `labels_indices`， `labels_values`， `sequence_length`，如何使用`CTCLoss`进行训练？", "response": "定义的`model.train`接口里接收的`dataset`可以是多个数据组成，形如(`data1`， `data2`， `data3`， ...)，所以`dataset`是可以包含`inputs`，`labels_indices`，`labels_values`，`sequence_length`的信息的。只需要定义好相应形式的`dataset`，传入`model.train`里就可以。具体的可以了解下相应的[数据处理接口](https://www.mindspore.cn/tutorials/zh-CN/master/advanced/dataset.html)", "history": []}
{"prompt": "模型转移时如何把PyTorch的权重加载到MindSpore中？", "response": "首先输入PyTorch的`pth`文件，以`ResNet-18`为例，MindSpore的网络结构和PyTorch保持一致，转完之后可直接加载进网络，这边参数只用到`BN`和`Conv2D`，若有其他层`ms`和PyTorch名称不一致，需要同样的修改名称。", "history": []}
{"prompt": "MindSpore有哪些现成的推荐类或生成类网络或模型可用？", "response": "目前正在开发Wide & Deep、DeepFM、NCF等推荐类模型，NLP领域已经支持Bert_NEZHA，正在开发MASS等模型，用户可根据场景需要改造为生成类网络，可以关注[MindSpore ModelZoo](https://gitee.com/mindspore/models/blob/master/README_CN.md#)。", "history": []}
{"prompt": "如何使用MindSpore拟合$f(x)=a \\times sin(x)+b$这类函数？", "response": "以下拟合案例是基于MindSpore线性拟合官方案例改编而成。\t```python\t# The fitting function is: f(x)=2*sin(x)+3.\timport numpy as np\tfrom mindspore import dataset as ds\tfrom mindspore.common.initializer import Normal\tfrom mindspore import nn， Model， set_context， GRAPH_MODE\tfrom mindspore.train.callback import LossMonitor\t\tset_context(mode=GRAPH_MODE， device_target=\"CPU\")\t\t def get_data(num， w=2.0， b=3.0):\t    # f(x)=w * sin(x) + b\t    # f(x)=2 * sin(x) +3\t    for i in range(num):\t        x = np.random.uniform(-np.pi， np.pi)\t        noise = np.random.normal(0， 1)\t        y = w * np.sin(x) + b + noise\t        yield np.array([np.sin(x)]).astype(np.float32)， np.array([y]).astype(np.float32)\t\tdef create_dataset(num_data， batch_size=16， repeat_size=1):\t    input_data = ds.GeneratorDataset(list(get_data(num_data))， column_names=['data'，'label'])\t    input_data = input_data.batch(batch_size)\t    input_data = input_data.repeat(repeat_size)\t    return input_data\t\tclass LinearNet(nn.Cell):\t    def __init__(self):\t        super(LinearNet， self).__init__()\t        self.fc = nn.Dense(1， 1， Normal(0.02)， Normal(0.02))\t\t    def construct(self， x):\t        x = self.fc(x)\t        return x\t\tif __name__ == \"__main__\":\t    num_data = 1600\t    batch_size = 16\t    repeat_size = 1\t    lr = 0.005\t    momentum = 0.9\t\t    net = LinearNet()\t    net_loss = nn.loss.MSELoss()\t    opt = nn.Momentum(net.trainable_params()， lr， momentum)\t    model = Model(net， net_loss， opt)\t\t    ds_train = create_dataset(num_data， batch_size=batch_size， repeat_size=repeat_size)\t\t    model.train(1， ds_train， callbacks=LossMonitor()， dataset_sink_mode=False)\t\t    print(net.trainable_params()[0]， \"\\n%s\" % net.trainable_params()[1])\t```", "history": []}
{"prompt": "如何使用MindSpore拟合$f(x)=ax^2+bx+c$这类的二次函数？", "response": "以下代码引用自MindSpore的官方教程的[代码仓](https://gitee.com/mindspore/docs/blob/master/docs/sample_code/linear_regression.py)\t在以下几处修改即可很好的拟合$f(x)=ax^2+bx+c$:\t1. 数据集生成。\t2. 拟合网络。\t3. 优化器。\t修改的详细信息如下，附带解释。\t```python\t# Since the selected optimizer does not support CPU， so the training computing platform is changed to GPU， which requires readers to install the corresponding GPU version of MindSpore.\tcontext.set_context(mode=context.GRAPH_MODE， device_target=\"GPU\")\t\t# Assuming that the function to be fitted this time is f(x)=2x^2+3x+4， the data generation function is modified as follows:\tdef get_data(num， a=2.0， b=3.0 ，c = 4):\t    for i in range(num):\t        x = np.random.uniform(-10.0， 10.0)\t        noise = np.random.normal(0， 1)\t        # The y value is generated by the fitting target function ax^2+bx+c.\t        y = x * x * a + x * b + c + noise\t        # When a*x^2+b*x+c is fitted， a and b are weight parameters and c is offset parameter bias. The training data corresponding to the two weights are x^2 and x respectively， so the dataset generation mode is changed as follows:\t        yield np.array([x*x， x]).astype(np.float32)， np.array([y]).astype(np.float32)\t\tdef create_dataset(num_data， batch_size=16， repeat_size=1):\t    input_data = ds.GeneratorDataset(list(get_data(num_data))， column_names=['data'，'label'])\t    input_data = input_data.batch(batch_size)\t    input_data = input_data.repeat(repeat_size)\t    return input_data\t\tclass LinearNet(nn.Cell):\t    def __init__(self):\t        super(LinearNet， self).__init__()\t        # Because the full join function inputs two training parameters， the input value is changed to 2， the first Nomral(0.02) will automatically assign random weights to the input two parameters， and the second Normal is the random bias.\t        self.fc = nn.Dense(2， 1， Normal(0.02)， Normal(0.02))\t\t    def construct(self， x):\t        x = self.fc(x)\t        return x\t\tif __name__ == \"__main__\":\t    num_data = 1600\t    batch_size = 16\t    repeat_size = 1\t    lr = 0.005\t    momentum = 0.9\t\t    net = LinearNet()\t    net_loss = nn.loss.MSELoss()\t    # RMSProp optimalizer with better effect is selected for quadratic function fitting， Currently， Ascend and GPU computing platforms are supported.\t    opt = nn.RMSProp(net.trainable_params()， learning_rate=0.1)\t    model = Model(net， net_loss， opt)\t\t    ds_train = create_dataset(num_data， batch_size=batch_size， repeat_size=repeat_size)\t    model.train(1， ds_train， callbacks=LossMonitor()， dataset_sink_mode=False)\t\t    print(net.trainable_params()[0]， \"\\n%s\" % net.trainable_params()[1])\t```", "history": []}
{"prompt": "`mindspore/tests`下怎样执行单个`ut`用例？", "response": "`ut`用例通常需要基于debug版本的MindSpore包，官网并没有提供。可以基于源码使用`sh build.sh`编译，然后通过`pytest`指令执行，debug模式编包不依赖后端。编译选项`sh build.sh -t on`，用例执行可以参考`tests/runtest.sh`脚本。", "history": []}
{"prompt": "在Ascend平台上，执行用例有时候会报错`run task error`，如何获取更详细的日志帮助问题定位？", "response": "使用msnpureport工具设置device侧日志级别，工具位置在: `/usr/local/Ascend/latest/driver/tools/msnpureport`。\t- 全局级别:\t```bash\t/usr/local/Ascend/latest/driver/tools/msnpureport -g info\t```- 模块级别:\t```bash\t/usr/local/Ascend/latest/driver/tools/msnpureport -m SLOG:error\t````- Event级别:\t```bash\t/usr/local/Ascend/latest/driver/tools/msnpureport -e disable/enable\t```- 多device id级别:\t```bash\t/usr/local/Ascend/latest/driver/tools/msnpureport -d 1 -g warning\t```假设deviceID的取值范围是[0-7]，`device0`-`device3`和`device4`-`device7`分别在一个os上。其中`device0`-`device3`共用一个日志配置文件；`device4`-`device7`共用一个配置文件。如果修改了`device0`-`device3`中的任意一个日志级别，其他`device`的日志级别也会被修改。如果修改了`device4`-`device7`中的任意一个日志级别，其他device的日志级别也会被修改。\t`Driver`包安装以后（假设安装路径为/usr/local/HiAI，在Windows环境下，`msnpureport.exe`执行文件在C:\\ProgramFiles\\Huawei\\Ascend\\Driver\\tools\\目录下），假设用户在/home/shihangbo/目录下直接执行命令行，则Device侧日志被导出到当前目录下，并以时间戳命名文件夹进行存放。", "history": []}
{"prompt": "使用Ascend平台执行训练过程，出现报错: `Out of Memory!!! total[3212254720] (dynamic[0] memory poll[524288000]) malloc[32611480064] failed!` 如何解决？", "response": "此问题属于内存占用过多导致的内存不够问题，可能原因有两种:\t- `batch_size`的值设置过大。解决办法: 将`batch_size`的值设置减小。\t- 引入了异常大的`Parameter`，例如单个数据shape为[640，1024，80，81]，数据类型为float32，单个数据大小超过15G，这样差不多大小的两个数据相加时，占用内存超过3*15G，容易造成`Out of Memory`。解决办法: 检查参数的`shape`，如果异常过大，减少shape。\t- 如果以上操作还是未能解决，可以上[官方论坛](https://bbs.huaweicloud.com/forum/forum-1076-1.html)发帖提出问题，将会有专门的技术人员帮助解决。", "history": []}
{"prompt": "如何在训练神经网络过程中对计算损失的超参数进行改变？", "response": "您好，很抱歉暂时还未有这样的功能。目前只能通过训练-->重新定义优化器-->训练，这样的过程寻找较优的超参数。", "history": []}
{"prompt": "运行应用时报错`error while loading shared libraries: libge_compiler.so: cannot open shared object file: No such file or directory`怎么办？", "response": "安装MindSpore所依赖的Ascend 310 AI处理器配套软件包时，`CANN`包不能安装`nnrt`版本，而是需要安装功能完整的`toolkit`版本。", "history": []}
{"prompt": "MindSpore代码里面的model_zoo/official/cv/resnet/train.py中context.set_ps_context(enable_ps=True)为什么一定要在init之前设置", "response": "MindSpore Ascend模式下，如果先调用init，那么会为所有的进程都分配卡，但是parameter server训练模式下server是不需要分配卡的，那么worker和server就会去使用同一块卡，导致会报错: HCCL dependent tsd is not open。", "history": []}
{"prompt": "在CPU ARM平台上进行resnet50训练，内存持续增长怎么办？", "response": "在CPU ARM上进行resnet50训练时，部分算子的实现是基于oneDNN库，oneDNN库中是基于libgomp库实现多线程并行，当前libgomp存在多个并行域配置的线程数不同时有内存占用持续增长的问题。可通过全局配置统一的线程数来控制内存的持续增长。再综合性能上的考虑，建议统一配置为物理核数的1/4，比如`export OMP_NUM_THREADS=32`。", "history": []}
{"prompt": "为什么在Ascend平台执行模型时报流超限的错误？", "response": "流表示一个操作队列，同一条流上的任务按序串行执行，不同流之间可以并行执行。网络中的各种操作会生成Task并被分配到流上，以控制任务执行的并发方式。由于Ascend平台对同一条流上的的任务数存在限制，超限的任务会分配新流，且MindSpore框架的多种并行方式也会分配新流，例如通信算子并行，因此当分配流的数目超过Ascend平台的资源限制就会报流超限的错误。参考解决方案：\t- 减小网络模型规模\t\t- 减少网络中通信算子的使用\t\t- 减少网络中的条件控制语句", "history": []}
{"prompt": "在Ascend平台上，日志中出现报错“Ascend error occurred， error message:”且跟随了一个错误码，如“E40011”，如何查找出现错误码的原因？", "response": "当出现“Ascend error occurred， error message:”时，说明昇腾CANN相关模块出现异常，上报了错误日志。\t此时错误码后有异常的错误信息。如果需要该异常更详细的可能原因和处理方法，请参考对应昇腾版本文档的《Error Code故障处理》部分，如[昇腾CANN社区版(5.0.3 alpha 002)(训练) Error Code故障处理](https://support.huaweicloud.com/trouble-cann503alpha2training/atlaspd_15_0001.html)。", "history": []}
{"prompt": "训练nlp类网络，当使用第三方组件gensim时，可能会报错: ValueError，如何解决？", "response": "以下为报错信息:\t```bash\t>>> import gensim\tTraceback (most recent call last):\t  File \"<stdin>\"， line 1， in <module>\t  File \"/home/miniconda3/envs/ci39_cj/lib/python3.9/site-packages/gensim/__init__.py\"， line 11， in <module>\t    from gensim import parsing， corpora， matutils， interfaces， models， similarities， utils  # noqa:F401\t  File \"/home/miniconda3/envs/ci39_cj/lib/python3.9/site-packages/gensim/corpora/__init__.py\"， line 6， in <module>\t    from .indexedcorpus import IndexedCorpus  # noqa:F401 must appear before the other classes\t  File \"/home/miniconda3/envs/ci39_cj/lib/python3.9/site-packages/gensim/corpora/indexedcorpus.py\"， line 14， in <module>\t    from gensim import interfaces， utils\t  File \"/home/miniconda3/envs/ci39_cj/lib/python3.9/site-packages/gensim/interfaces.py\"， line 19， in <module>\t    from gensim import utils， matutils\t  File \"/home/miniconda3/envs/ci39_cj/lib/python3.9/site-packages/gensim/matutils.py\"， line 1024， in <module>\t    from gensim._matutils import logsumexp， mean_absolute_difference， dirichlet_expectation\t  File \"gensim/_matutils.pyx\"， line 1， in init gensim._matutils\tValueError: numpy.ndarray size changed， may indicate binary incompatibility. Expected 88 from C header， got 80 from PyObject\t```报错原因请参考[gensim](https://github.com/RaRe-Technologies/gensim/issues/3095)官网，或者[numpy](https://github.com/numpy/numpy/issues/18709)官网:\t解决方案:\t方法一: 重新安装numpy及gensim， 执行命令: `pip uninstall gensim numpy -y && pip install numpy gensim` ；\t方法二: 如果还是有问题，请删除wheel安装包的缓存文件，然后执行方法一（wheel安装包缓存目录为: `~/.cache/pip/wheels`）。", "history": []}
{"prompt": "运行文档示例代码的过程中，遇到`matplotlib.pyplot.show()`或`plt.show()`无法执行怎么处理？", "response": "首先确认是否安装`matplotlib`，如果没有安装，可以在命令行中执行`pip install matplotlib`进行安装。\t其次由于`matplotlib.pyplot.show()`的作用是以图形化方式展示，所以需要运行系统支持图形展示功能，如果系统不能支持图形展示，需要将该\t图形展示的命令行注释后再运行，不影响整体代码的运行结果。", "history": []}
{"prompt": "使用文档中提供的在线运行时，遇到运行失败该如何处理？", "response": "需要确认有做以下准备工作。\t- 首先，需要通过华为云账号登录ModelArts。\t- 其次，注意教程文档的标签中列举的硬件环境，以及样例代码中配置的硬件环境，是Ascend、GPU还是CPU，由于登录后默认使用的硬件环境是CPU，Ascend环境和GPU环境需要用户手动点击切换。\t- 最后，确保当前`Kernel`为MindSpore。\t完成上述步骤后，就可以运行文档了。\t具体的操作过程可以参考[基于ModelArts在线体验MindSpore](https://bbs.huaweicloud.com/forum/thread-168982-1-1.html)。", "history": []}
{"prompt": "静态图下使用除法结果未报错，动态图下使用除法结果却报错？", "response": "在静态图模式下，由于使用的是静态编译，对于算子输出结果的数据类型是在图编译阶段确定的。\t例如如下代码在静态图模式下执行，输入数据的类型都为int类型，根据静态图编译，其输出结果也是int类型。\t```python\tfrom mindspore import set_context， GRAPH_MODE\tfrom mindspore import nn\t\tset_context(mode=GRAPH_MODE， device_target=\"CPU\")\t\tclass MyTest(nn.Cell):\t    def __init__(self):\t        super(MyTest， self).__init__()\t\t    def construct(self， x， y):\t        return x / y\tx = 16\ty = 4\tnet = MyTest()\toutput = net(x， y)\tprint(output， type(output))\t```输出结果：\t```text\t4 <class 'int'>\t```修改执行模式，将GRAPH_MODE修改成PYNATIVE_MODE，由于在动态图模式下使用的Python语法执行，Python语法对任意除法输出的类型都是float类型，因此执行结果如下：\t```text\t4.0 <class 'float'>\t```因此在后续算子明确需要使用int的场景下，建议使用Python的整除符号`//`。", "history": []}
{"prompt": "在Ascend310硬件平台安装了MindSpore1.3版本，运行mindspore_serving中的`add_model.py`样例出现报错？", "response": "Ascend310上支持模型导出、Serving推理，但是不支持MindSpore前端Python脚本直接推理，`add`样例中导出模型多了MindSpore前端Python脚本直接推理的代码，在Ascend310场景注释掉即可。\t```python\tdef export_net():\t    \"\"\"Export add net of 2x2 + 2x2， and copy output model `tensor_add.mindir` to directory ../add/1\"\"\"\t    x = np.ones([2， 2]).astype(np.float32)\t    y = np.ones([2， 2]).astype(np.float32)\t    add = Net()\t    # MindSpore前端Python脚本直接推理，310注释掉\t    # output = add(ms.Tensor(x)， ms.Tensor(y))\t    ms.export(add， ms.Tensor(x)， ms.Tensor(y)， file_name='tensor_add'， file_format='MINDIR')\t    dst_dir = '../add/1'\t    try:\t        os.mkdir(dst_dir)\t    except OSError:\t        pass\t\t    dst_file = os.path.join(dst_dir， 'tensor_add.mindir')\t    copyfile('tensor_add.mindir'， dst_file)\t    print(\"copy tensor_add.mindir to \" + dst_dir + \" success\")\t\t    print(x)\t    print(y)\t    # print(output.asnumpy())。\t```", "history": []}
{"prompt": "编译应用时报错`/usr/bin/ld: warning: libxxx.so， needed by libmindspore.so， not found`怎么办？", "response": "寻找缺少的动态库文件所在目录，添加该路径到环境变量`LD_LIBRARY_PATH`中，环境变量设置参考[Ascend 310 AI处理器上使用MindIR模型进行推理#编译推理代码](https://www.mindspore.cn/tutorials/experts/zh-CN/master/infer/ascend_310_mindir.html#编译推理代码)。", "history": []}
{"prompt": "运行应用时报错`error while loading shared libraries: libge_compiler.so: cannot open shared object file: No such file or directory`怎么办？", "response": "安装MindSpore所依赖的Ascend 310 AI处理器配套软件包时，`CANN`包不能安装`nnrt`版本，而是需要安装功能完整的`toolkit`版本。", "history": []}
{"prompt": "使用昇腾310进行推理的时候怎么设置高精度或者高性能模式？", "response": "在推理代码中通过Ascend310DeviceInfo中的SetPrecisionMode接口进行设置，可选：force_fp16、allow_fp32_to_fp16、must_keep_origin_dtype，allow_mix_precision。默认值为force_fp16，指的就是高性能模式。高精度模式可设置为allow_fp32_to_fp16或must_keep_origin_dtype。", "history": []}
{"prompt": "AIPP文件怎么配置？", "response": "AIPP（Artificial Intelligence Pre-Processing）AI预处理，用于在AI Core上完成图像预处理，包括改变图像尺寸、色域转换（转换图像格式）、减均值/乘系数（改变图像像素），数据处理之后再进行真正的模型推理。相关的配置介绍比较复杂，可以参考[ATC工具的AIPP使能章节](https://support.huaweicloud.com/atctool-cann502alpha3infer/atlasatc_16_0015.html)。", "history": []}
{"prompt": "怎么设置昇腾310推理过程中的日志级别？", "response": "通过ASCEND_GLOBAL_LOG_LEVEL来设置，0：DEBUG级别；1：INFO级别；2：WARNING级别；3：ERROR级别；4：NULL级别，不输出日志；其他值为非法值。配置示例：export ASCEND_GLOBAL_LOG_LEVEL=1。如果推理过程中出现错误可通过修改日志级别来获取更详细的日志信息。", "history": []}
{"prompt": "安装MindSpore版本: GPU、CUDA 10.1、0.5.0-beta，出现问题: `cannot open shared object file:No such file or directory`。", "response": "从报错情况来看，是cuBLAS库没有找到。一般的情况下是cuBLAS库没有安装，或者是因为没有加入到环境变量中去。通常cuBLAS是随着CUDA以及驱动一起安装的，确认安装后把cuBLAS所在的目录加入`LD_LIBRARY_PATH`环境变量中即可。", "history": []}
{"prompt": "使用pip安装时报错: `ERROR: mindspore_{VERSION}.whl is not a supported wheel on this platform`应该怎么办？", "response": "pip会通过wheel安装包的文件名来判断该安装包是否与当前Python环境兼容，例如安装mindspore_ascend-1.2.0-cp37-cp37m-linux_aarch64.whl时，pip会检查:\t1. 当前python环境为3.7.x版本\t2. 当前操作系统为Linux\t3. 操作系统架构为arm64\t因此，如果出现 `is not a supported wheel on this platform` 问题，请检查当前环境是否满足MindSpore安装要求，以及该MindSpore安装包版本是否正确。", "history": []}
{"prompt": "macOS系统源码编译后使用pip安装报错: `ERROR: mindspore-{VERSION}.whl is not a supported wheel on this platform`应该怎么办？", "response": "首先检查output目录下编译得到的安装包名，类似mindspore-1.6.0-cp37-cp37m-macosx_11_1_x84_64.whl。包名中“11_1”的意思是编译时使用的SDK版本是11.1。如果使用的SDK版本为11.x，则可能是因为编译时使用的SDK版本过高导致无法安装。\t解决方法一：可以重命名安装包后再尝试安装，例如将上述安装包重命名为mindspore-1.6.0-cp37-cp37m-macosx_10_15_x84_64.whl。\t解决方法二：在源码编译前，设置环境变量`MACOSX_DEPOLYMENT_TARGET`为`10.15`并重新编译。", "history": []}
{"prompt": "arm64架构的macOS系统使用pip安装SciPy依赖库时报错，应该怎么办？", "response": "SciPy当前没有对应macOS系统arm64架构的whl包，可以使用第三方编译的whl包进行安装。执行如下命令先安装SciPy，再重新安装MindSpore。\t```bash\tpip install --pre -i https://pypi.anaconda.org/scipy-wheels-nightly/simple scipy\t```", "history": []}
{"prompt": "使用pip安装时报错: `SSL:CERTIFICATE_VERIFY_FATLED`应该怎么办？", "response": "在pip安装命令后添加参数 `--trusted-host=ms-release.obs.cn-north-4.myhuaweicloud.com`重试即可。", "history": []}
{"prompt": "MindSpore对Protobuf版本是否有特别要求？", "response": "MindSpore默认安装Protobuf的3.13.0版本，如果不是该版本，在使用pytest测试代码时日志中会产生很多告警，建议您使用命令`pip install protobuf==3.13.0`重新安装3.13.0版本。", "history": []}
{"prompt": "使用pip安装时报错`ProxyError(Cannot connect to proxy)`，应该怎么办？", "response": "此问题一般是代理配置问题，Ubuntu环境下可通过`export http_proxy={your_proxy}`设置代理；Windows环境可以在cmd中通过`set http_proxy={your_proxy}`进行代理设置。", "history": []}
{"prompt": "使用pip安装时提示错误，应该怎么办？", "response": "请执行`pip -V`查看是否绑定了Python3.7+。如果绑定的版本不对，建议使用`python3.7 -m pip install`代替`pip install`命令。", "history": []}
{"prompt": "使用pip安装依赖库时提示`No matching distribution found for XXX`错误，应该怎么办？", "response": "请执行`pip config list`，查看当前软件库索引路径`index-url`。某些情况下，软件库索引会出现更新滞后，可尝试设置其它软件库索引路径。", "history": []}
{"prompt": "MindSpore网站安装页面找不到MindInsight和MindArmour的whl包，无法安装怎么办？", "response": "您可以从[MindSpore网站下载地址](https://www.mindspore.cn/versions)下载whl包，通过`pip install`命令进行安装。", "history": []}
{"prompt": "MindSpore是否支持Nvidia GPU独立显卡+Windows操作系统的个人电脑？", "response": "目前MindSpore支持的情况是GPU+Linux与CPU+Windows的组合配置，Windows+GPU的支持还在开发中。\t如果希望在GPU+Windows的环境上运行，可以尝试使用WSL+docker的方式，操作思路:\t1. 以WSL方式安装起Ubuntu18.04，参考<https://docs.microsoft.com/en-us/windows/wsl/install-win10>。\t2. 安装支持WSL的Nvidia驱动以及在WSL运行容器的环境部署，参考<https://docs.nvidia.com/cuda/wsl-user-guide/index.html>。\t\t   > 由于CUDA on WSL还是预览特性，注意参考链接里对Windows版本要求的说明，版本不够的需要做升级。\t3. 参考<https://gitee.com/mindspore/mindspore#docker镜像>，取MindSpore-GPU镜像。如取MindSpore1.0.0版本容器，在WSL Ubuntu18.04中执行`docker pull mindspore/mindspore-gpu:1.0.0`运行容器:\t\t    ```docker\t    docker run -it --runtime=nvidia mindspore/mindspore-gpu:1.0.0 /bin/bash\t    ```详细步骤可以参考社区提供的实践[张小白教你安装Windows10的GPU驱动（CUDA和cuDNN）](https://bbs.huaweicloud.com/blogs/212446)。\t在此感谢社区成员[张辉](https://bbs.huaweicloud.com/community/usersnew/id_1552550689252345)的分享。", "history": []}
{"prompt": "Ascend硬件平台，在个人的Conda环境中，有时候出现报错RuntimeError: json.exception.parse_error.101 parse error at line 1， column 1: syntax error while parsing value - invalid literal; last read: 'T'，该怎么处理？", "response": "出现这种类型的报错，大概率是run包更新后个人的Conda环境中没有更新te或topi或hccl工具包，可以将当前Conda环境中的上述几个工具包卸载，然后使用如下命令再重新安装: `pip install /usr/local/Ascend/ascend-toolkit/latest/fwkacllib/lib64/{te/topi/hccl}-{version}-py3-none-any.whl`。", "history": []}
{"prompt": "pip同时安装MindSpore CPU和GPU版本，import时报错 `cannot import name 'context' from 'mindspore'`，应该怎么办？", "response": "MindSpore不同版本的安装目录名同为`mindspore`，安装在同一个Python环境可能产生目录相互覆盖问题，导致无法使用，如果需要使用多平台版本的MindSpore时（例如同时使用CPU和GPU版本），请先卸载其他版本再安装新版本。", "history": []}
{"prompt": "在ARM架构的环境上使用pip安装MindSpore时报错: `Could not find a version that satisfies the requirement`应该怎么办？", "response": "大概率是因为pip版本低于19.3，无法识别`manylinux2014`标签，导致pip install阶段下载了错误版本的`numpy`或`scipy`等python软件包，进而引发了无法找到构建依赖的问题，请执行`pip install --upgrade pip`将环境中的pip升级到19.3以上，重新安装MindSpore。", "history": []}
{"prompt": "pip安装MindSpore时，报错 `Running setup.py install for pillow: finished with status 'error' ... The headers or library files could not be found for jpeg， ...`，应该怎么办？", "response": "MindSpore依赖三方库`pillow`进行部分的数据处理操作，而`pillow`需要依赖环境上已经安装`libjpeg`库，以Ubuntu环境为例，可以使用`sudo apt-get install libjpeg8-dev`来安装`libjpeg`库，然后再安装MindSpore。", "history": []}
{"prompt": "编译时`bash -p`方式和 `bash -e`方式的区别？", "response": "MindSpore Serving的编译和运行依赖MindSpore，Serving提供两种编译方式: 一种指定已安装的MindSpore路径，即`bash -p {python site-packages}/mindspore/lib`，避免编译Serving时再编译MindSpore；另一种，编译Serving时，编译配套的MindSpore，Serving会将`-e`、`-V`和`-j`选项透传给MindSpore。\t比如，在Serving目录下，`bash -e ascend -V 910 -j32`:\t- 首先将会以`bash -e ascend -V 910 -j32`方式编译`third_party/mindspore`目录下的MindSpore；\t- 其次，编译脚本将MindSpore编译结果作为Serving的编译依赖。", "history": []}
{"prompt": "在Linux中已经安装了交叉编译工具，但是编译命令要怎么写呢？", "response": "arm64版本编译: `bash build.sh -I arm64`；arm32版本编译: `bash build.sh -I arm32`；注意要先设置环境变量，指定Android NDK路径: `export ANDROID_NDK=/path/to/android-ndk`，编译成功后，在output目录可以找到编译出的包。", "history": []}
{"prompt": "MindSpore安装: 版本0.6.0-beta + Ascend 910 + Ubuntu_aarch64 + Python3.7.5，手动下载对应版本的whl包，编译并安装gmp6.1.2。其他Python库依赖已经安装完成，执行样例失败，报错显示找不到so文件。", "response": "`libdatatransfer.so`动态库是`fwkacllib/lib64`目录下的，请先在`/usr/local`目录查找到这个库所在的路径，然后把这个路径加到`LD_LIBRARY_PATH`环境变量中，确认设置生效后，再执行。", "history": []}
{"prompt": "源码编译MindSpore过程时间过长，或时常中断该怎么办？", "response": "MindSpore通过submodule机制引入第三方依赖包，其中`Protobuf`依赖包（v3.13.0）下载速度不稳定，建议您提前进行包缓存。", "history": []}
{"prompt": "如何改变第三方依赖库安装路径？", "response": "第三方依赖库的包默认安装在build/mindspore/.mslib目录下，可以设置环境变量MSLIBS_CACHE_PATH来改变安装目录，比如 `export MSLIBS_CACHE_PATH = ~/.mslib`。", "history": []}
{"prompt": "MindSpore要求的配套软件版本与Ubuntu默认版本不一致怎么办？", "response": "当前MindSpore只提供版本配套关系，需要您手动进行配套软件的安装升级。（**注明**: MindSpore要求Python3.7.5和gcc7.3，Ubuntu 16.04默认为Python3.5和gcc5，Ubuntu 18.04默认自带Python3.7.3和gcc7.4）。", "history": []}
{"prompt": "执行用例报错`No module named 'mindpore.version'`，应该怎么办？", "response": "当有这种报错时，有可能是在创建了和MindSpore安装包相同名字的路径中执行用例，导致Python导入包的时候优先找到了当前目录下，而当前目录没有version.py这个文件。解决方法就是目录重命名或者向上退出一级或者多级目录。", "history": []}
{"prompt": "源码编译时，报错`MD5 does not match`，应该怎么办？", "response": "这种报错可能是在编译的时候由于网络问题导致一些第三方库下载中断，之后重新编译的时候，该文件已经存在但是不完整，在校验MD5的时候失败。解决方法是: 删除.mslib缓存路径中的相关第三方库，然后重新编译。", "history": []}
{"prompt": "环境上安装了Python3.7.5，环境变量设置正确，编译MindSpore时仍然报错`Python3 not found`，应该怎么办？", "response": "可能是因为当前环境上的Python未包含动态库。编译MindSpore需要动态链接Python库，因此需要使用开启动态库编译选项的Python3.7.5，即在源码编译Python时使用`./configure --enable-shared`命令。", "history": []}
{"prompt": "编译失败后，应该清理哪些路径以确保上次失败的编译结果不会影响到下一次编译？", "response": "在编译MindSpore时，如果:\t1. 第三方组件下载或编译失败，例如icu4c的patch动作失败返回错误信息`Cmake Error at cmake/utils.cmake:301 (message): Failed patch:`，则进入编译目录下的`build/mindspore/.mslib`目录，或由`MSLIBS_CACHE_PATH`环境变量指定的第三方软件安装目录，并删除其中的对应软件。\t\t2. 其他阶段编译失败，或打算删除上一次编译结果，完全重新编译时，直接删除`build`目录即可。", "history": []}
{"prompt": "编译时报错，打开CMakeError.txt提示pthread找不到怎么办？", "response": "真正的失败原因会体现在打屏的日志里，CMakeError.txt无参考价值，请寻找打屏日志中的第一个报错。", "history": []}
{"prompt": "编译成功后，运行时报错`undefined reference to XXXX`或`undefined symbol XXXX`怎么办？", "response": "可能的原因有:\t1. 如果问题是`git pull`更新代码后出现，请删除掉`build`文件夹，排除前次构建的影响。\t\t2. 如果问题是修改代码后出现，可以使用`c++filt XXXX`查看该符号的意义，有可能是函数未实现、虚函数未实现、依赖未链接等原因引起。\t\t3. 如果问题发生在Ascend平台，排除上述原因后，很可能是由于MindSpore版本与CANN版本不匹配引起的，版本匹配关系参考[安装说明](https://www.mindspore.cn/install)。", "history": []}
{"prompt": "如何卸载MindSpore？", "response": "首先请确定MindSpore的全称，例如gpu版本的MindSpore，可以执行命令`pip uninstall mindspore-gpu`进行卸载。", "history": []}
{"prompt": "一些常用的环境变量设置，在新启动的终端窗口中需要重新设置，容易忘记应该怎么办？", "response": "常用的环境变量设置写入到`~/.bash_profile` 或 `~/.bashrc`中，可让环境变量设置在新启动的终端窗口中立即生效。", "history": []}
{"prompt": "使用GPU版本MindSpore时，如何设置`DEVICE_ID`环境变量", "response": "MindSpore GPU模式一般无需设置`DEVICE_ID`环境变量，MindSpore会根据cuda环境变量`CUDA_VISIBLE_DEVICES`，自动选择可见的GPU设备。设置`CUDA_VISIBLE_DEVICES`环境变量后，则`DEVICE_ID`环境变量代表可见GPU设备的下标:\t- 执行`export CUDA_VISIBLE_DEVICES=1，3，5`后，`DEVICE_ID`应当被设置为`0`，`1`或`2`，若设置为`3`及以上，MindSpore会由于设备ID不合法而运行失败。", "history": []}
{"prompt": "编译应用时报错`/usr/bin/ld: warning: libxxx.so， needed by libmindspore.so， not found`怎么办？", "response": "寻找缺少的动态库文件所在目录，添加该路径到环境变量`LD_LIBRARY_PATH`中，环境变量设置参考[Ascend 310 AI处理器上使用MindIR模型进行推理#编译推理代码](https://www.mindspore.cn/tutorials/experts/zh-CN/master/infer/ascend_310_mindir.html#编译推理代码)。", "history": []}
{"prompt": "运行应用时出现`ModuleNotFoundError: No module named 'te'`怎么办？", "response": "首先确认环境安装是否正确，`te`、`topi`等whl包是否正确安装。如果用户环境中有多个Python版本，如Conda虚拟环境中，需`ldd name_of_your_executable_app`确认应用所链接的`libpython3.so`是否与当前Python路径一致，如果不一致需要调整环境变量`LD_LIBRARY_PATH`顺序，例如\t```bash\texport LD_LIBRARY_PATH=`python -c \"import distutils.sysconfig as sysconfig; print(sysconfig.get_config_var('LIBDIR'))\"`:$LD_LIBRARY_PATH\t```将当前的`python`命令对应程序的运行库路径加入到`LD_LIBRARY_PATH`的最前面。", "history": []}
{"prompt": "运行应用时出现`error while loading shared libraries: libpython3.so: cannot open shared object file: No such file or directory`怎么办？", "response": "该报错通常出现在装有多个Python版本的环境中，首先确认Python的`lib`目录是否在环境变量`LD_LIBRARY_PATH`中，可执行以下命令进行设置：\t```bash\texport LD_LIBRARY_PATH=`python -c \"import distutils.sysconfig as sysconfig; print(sysconfig.get_config_var('LIBDIR'))\"`:$LD_LIBRARY_PATH\t```另外如果在Conda虚拟环境中，Python 3.7.6以下版本不含该动态库，可以执行命令升级Conda中Python的版本，如：`conda install python=3.7.11`。", "history": []}
{"prompt": "Ascend AI处理器配套软件包与其他依赖软件已安装，但是执行MindSpore时提示`Cannot open shared objectfile: No such file or directory`该怎么办？", "response": "常见原因有两种: Ascend AI处理器配套软件包或固件/驱动包版本不正确，或没有安装在默认位置且未配置相应的环境变量。\t1. 打开Ascend AI处理器配套软件包安装目录，默认`/usr/local/Ascend`下，各个子目录中的`version.info`文件，观察其版本号是否与当前使用的MindSpore版本一直，参照[安装页面](https://www.mindspore.cn/install/)中关于Ascend AI处理器配套软件包版本的描述。如果版本不配套，请更换软件包或MindSpore版本。\t\t2. 检查Ascend AI处理器配套软件包与其他依赖软件是否安装在默认位置，MindSpore会尝试从默认安装位置`/usr/local/Ascend`自动加载，如果将Ascend软件包安装在自定义位置，请参照[安装页面](https://www.mindspore.cn/install/)页面的安装指南一栏设置环境变量。如果将其他依赖软件安装在自定义位置，请根据其位置关系设置`LD_LIBRARY_PATH`环境变量。", "history": []}
{"prompt": "MindSpore的GPU版本对设备的计算能力有限制吗？", "response": "目前MindSpore仅支持计算能力大于5.3的设备。", "history": []}
{"prompt": "个人电脑CPU环境安装MindSpore后验证代码时报错: `the pointer[session] is null`，具体代码如下，该如何验证是否安装成功呢？", "response": "```python\timport numpy as np\tfrom mindspore import Tensor， set_context\timport mindspore.ops as ops\t\tset_context(device_target=\"Ascend\")\tx = Tensor(np.ones([1，3，3，4]).astype(np.float32))\ty = Tensor(np.ones([1，3，3，4]).astype(np.float32))\tprint(ops.add(x，y))\t```验证安装是否成功，可以参照对应版本的安装指南页面中 `验证是否成功安装` 段落的描述：\t```bash\tpython -c \"import mindspore;mindspore.run_check()\"\t```如果输出：\t```text\tMindSpore version: 版本号\tThe result of multiplication calculation is correct， MindSpore has been installed successfully!\t```说明MindSpore安装成功了。", "history": []}
{"prompt": "`Linux`平台下执行用例的时候会报错`sh:1:python:not found`或者由于链接到了Python2.7的版本中而报错`No module named mindspore._extends.remote`，该怎么处理？", "response": "遇到类似的问题，大多是由于Python的环境问题，可以通过如下方式检查Python环境是否是MindSpore运行时所需要的环境。\t- 在终端窗口中输入`python`，检查以下进入Python交互环境中的版本信息，如果直接报错则是没有Python的软连接；如果进入的是非Python3.7版本的环境，则当前Python环境不是MindSpore运行所需要的。\t- 执行`sudo ln -sf /usr/bin/python3.7.x /usr/bin/python`创建Python的软连接，然后再检查执行。", "history": []}
{"prompt": "在脚本中`import mindspore`之前import了其他三方库，提示如下错误(`/{your_path}/libgomp.so.1: cannot allocate memory in static TLS block`)该怎么解决?", "response": "上述问题较为常见，当前有两种可行的解决方法，可任选其一:\t- 交换import的顺序，先`import mindspore`再import其他三方库。\t- 执行程序之前先添加环境变量（`export LD_PRELOAD=/{your_path}/libgomp.so.1`），其中`{your_path}`是上述报错提示的路径。", "history": []}
{"prompt": "mindspore和gmp都已经通过源码编译安装后，在脚本中执行`import mindspore`，\t提示如下错误(`ImportError: libgmpxx.so: cannot open shared object file: No such file or directory`)该怎么解决?", "response": "上述问题的原因是在编译安装gmp库的时候没有设置`--enable-cxx`，正确的gmp编译安装方式如下（假设已经下载了gmp6.1.2安装包）：\t```bash\t$cd gmp-6.1.2\t$./configure --enable-cxx\t$make\t$make check\t$sudo make install\t```", "history": []}
{"prompt": "运行MindSpore时出现告警 `UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.` 应该怎么解决？", "response": "上述问题出现在安装了较新版本的numpy(>=1.22.0)版本的ARM python3.9环境上。告警来自numpy而非MindSpore。如果告警影响到了代码的正常调测，可以考虑手动安装较低版本的numpy(<=1.21.2)来规避。", "history": []}
{"prompt": "编译时报错“'self.xx' should be defined in the class '__init__' function.”怎么办？", "response": "如果在`construct`函数里，想对类成员`self.xx`赋值，那么`self.xx`必须已经在`__init__`函数中被定义为[Parameter](<https://www.mindspore.cn/docs/zh-CN/master/api_python/mindspore/mindspore.Parameter.html>)类型，其他类型则不支持。局部变量`xx`不受这个限制。", "history": []}
{"prompt": "编译时报错“This comparator 'AnyValue' is not supported. For statement 'is'， only support compare with 'None'， 'False' or 'True'”怎么办？", "response": "对于语法`is` 或 `is not`而言，当前`MindSpore`仅支持与`True`、`False`和`None`的比较。暂不支持其他类型，如字符串等。", "history": []}
{"prompt": "编译时报错“MindSpore does not support comparison with operators more than one now， ops size =2”怎么办？", "response": "对于比较语句，`MindSpore`最多支持一个操作数。例如不支持语句`1 < x < 3`，请使用`1 < x and x < 3`的方式代替。", "history": []}
{"prompt": "编译时报错“TypeError: The function construct need 1 positional argument and 0 default argument， but provided 2”怎么办？", "response": "网络的实例被调用时，会执行`construct`方法，然后会检查`construct`方法需要的参数个数和实际传入的参数个数，如果不一致则会抛出以上异常。\t请检查脚本中调用网络实例时传入的参数个数，和定义的网络中`construct`函数需要的参数个数是否一致。", "history": []}
{"prompt": "编译时报错“Type Join Failed”或“Shape Join Failed”怎么办？", "response": "在前端编译的推理阶段，会对节点的抽象类型(包含`type`、`shape`等)进行推导，常见抽象类型包括`AbstractScalar`、`AbstractTensor`、`AbstractFunction`、`AbstractTuple`、`AbstractList`等。在一些场景比如多分支场景，会对不同分支返回值的抽象类型进行`join`合并，推导出返回结果的抽象类型。如果抽象类型不匹配，或者`type`/`shape`不一致，则会抛出以上异常。\t当出现类似“Type Join Failed: dtype1 = Float32， dtype2 = Float16”的报错时，说明数据类型不一致，导致抽象类型合并失败。根据提供的数据类型和代码行信息，可以快速定位出错范围。此外，报错信息中提供了具体的抽象类型信息、节点信息，可以通过`analyze_fail.dat`文件查看MindIR信息，定位解决问题。关于MindIR的具体介绍，可以参考[MindSpore IR（MindIR）](https://www.mindspore.cn/docs/zh-CN/master/design/mindir.html)。代码样例如下:\t```python\timport numpy as np\timport mindspore as ms\timport mindspore.ops as ops\tfrom mindspore import nn， Tensor， set_context， GRAPH_MODE\t\tset_context(mode=GRAPH_MODE)\tclass Net(nn.Cell):\t    def __init__(self):\t        super().__init__()\t        self.relu = ops.ReLU()\t        self.cast = ops.Cast()\t\t    def construct(self， x， a， b):\t        if a > b:    # if的两个分支返回值的type不一致\t            return self.relu(x)    # shape: (2， 3， 4， 5)， dtype:Float32\t        else:\t            return self.cast(self.relu(x)， ms.float16)    # shape: (2， 3， 4， 5)， dtype:Float16\t\tinput_x = Tensor(np.random.rand(2， 3， 4， 5).astype(np.float32))\tinput_a = Tensor(2， ms.float32)\tinput_b = Tensor(6， ms.float32)\tnet = Net()\tout_me = net(input_x， input_a， input_b)\t```执行结果如下:\t```text\tTypeError: Cannot join the return values of different branches， perhaps you need to make them equal.\tType Join Failed: dtype1 = Float32， dtype2 = Float16.\tFor more details， please refer to the FAQ at https://www.mindspore.cn\tThe abstract type of the return value of the current branch is AbstractTensor(shape: (2， 3， 4， 5)， element: AbstractScalar(Type: Float16， Value: AnyValue， Shape: NoShape)， value_ptr: 0x55b9f289d090， value: AnyValue)， and that of the previous branch is AbstractTensor(shape: (2， 3， 4， 5)， element: AbstractScalar(Type: Float32， Value: AnyValue， Shape: NoShape)， value_ptr: 0x55b9f289d090， value: AnyValue).\tThe node is construct.6:[CNode]13{[0]: construct.6:[CNode]12{[0]: ValueNode<Primitive> Switch， [1]: [CNode]11， [2]: ValueNode<FuncGraph> ✓construct.4， [3]: ValueNode<FuncGraph> ✗construct.5}}， true branch: ✓construct.4， false branch: ✗construct.5\tThe function call stack:\tIn file test.py(14)/        if a > b:\t\tThe function call stack (See file 'analyze_fail.dat' for more details):\t# 0 In file test.py(14)\t        if a > b:\t        ^\t```当出现类似“Shape Join Failed: shape1 = (2， 3， 4， 5)， shape2 = ()”的报错时，说明`shape`不一致，导致抽象类型合并失败。代码样例如下:\t```python\timport numpy as np\timport mindspore as ms\timport mindspore.ops as ops\tfrom mindspore import nn， Tensor， set_context， GRAPH_MODE\t\tset_context(mode=GRAPH_MODE)\tclass Net(nn.Cell):\t    def __init__(self):\t        super().__init__()\t        self.relu = ops.ReLU()\t        self.reducesum = ops.ReduceSum()\t\t    def construct(self， x， a， b):\t        if a > b:    # if的两个分支返回值的shape不一致\t            return self.relu(x)    # shape: (2， 3， 4， 5)， dtype:Float32\t        else:\t            return self.reducesum(x)    # shape:()， dype: Float32\t\tinput_x = Tensor(np.random.rand(2， 3， 4， 5).astype(np.float32))\tinput_a = Tensor(2， ms.float32)\tinput_b = Tensor(6， ms.float32)\tnet = Net()\tout = net(input_x， input_a， input_b)\t``````text\tValueError: Cannot join the return values of different branches， perhaps you need to make them equal.\tShape Join Failed: shape1 = (2， 3， 4， 5)， shape2 = ().\tFor more details， please refer to the FAQ at https://www.mindspore.cn\tThe abstract type of the return value of the current branch is AbstractTensor(shape: ()， element: AbstractScalar(Type: Float32， Value: AnyValue， Shape: NoShape)， value_ptr: 0x55658aa9b090， value: AnyValue)， and that of the previous branch is AbstractTensor(shape: (2， 3， 4， 5)， element: AbstractScalar(Type: Float32， Value: AnyValue， Shape: NoShape)， value_ptr: 0x55658aa9b090， value: AnyValue).\tThe node is construct.6:[CNode]13{[0]: construct.6:[CNode]12{[0]: ValueNode<Primitive> Switch， [1]: [CNode]11， [2]: ValueNode<FuncGraph> ✓construct.4， [3]: ValueNode<FuncGraph> ✗construct.5}}， true branch: ✓construct.4， false branch: ✗construct.5\tThe function call stack:\tIn file test.py(14)/        if a > b:\t\tThe function call stack (See file 'analyze_fail.dat' for more details):\t# 0 In file test.py(14)\t        if a > b:\t        ^\t```当出现如“Type Join Failed: abstract type AbstractTensor can not join with AbstractTuple”的报错时，说明抽象类型不匹配，导致抽象类型合并失败，代码样例如下：\t```python\timport mindspore.ops as ops\tfrom mindspore import Tensor， ms_function\t\tx = Tensor([1.0])\ty = Tensor([2.0])\tgrad = ops.GradOperation(get_by_list=False， sens_param=True)\tsens = 1.0\t\tdef test_net(a， b):\t    return a， b\t\t@ms_function()\tdef join_fail():\t    sens_i = ops.Fill()(ops.DType()(x)， ops.Shape()(x)， sens)    # sens_i 是一个标量shape: (1)， dtype:Float64， value:1.0\t    # sens_i = (sens_i， sens_i)\t    a = grad(test_net)(x， y， sens_i)    # 对输出类型为tuple(Tensor， Tensor)的test_net求梯度需要sens_i的类型同输出保持一致，但sens_i是个Tensor; 在grad前设置sens_i = (sens_i， sens_i)可以修复问题。\t    return a\t\tjoin_fail()\t```执行结果如下：\t```text\tTypeError: Type Join Failed: abstract type AbstractTensor cannot join with AbstractTuple.\tFor more details， please refer to the FAQ at https://www.mindspore.cn.\tThis: AbstractTensor(shape: (1)， element: AbstractScalar(Type: Float32， Value: AnyValue， Shape: NoShape)， value_ptr: 0x56458a351ad0， value: Tensor(shape=[1]， dtype=Float32， value=[ 1.00000000e+00]))， other: AbstractTuple{element[0]: AbstractTensor(shape: (1)， element: AbstractScalar(Type: Float32， Value: AnyValue， Shape: NoShape)， value_ptr: 0x564583e3fa90， value: Tensor(shape=[1]， dtype=Float32， value=[ 1.00000000e+00]))， element[1]: AbstractTensor(shape: (1)， element: AbstractScalar(Type: Float32， Value: AnyValue， Shape: NoShape)， value_ptr: 0x564583cb00b0， value: Tensor(shape=[1]， dtype=Float32， value=[ 2.00000000e+00]))， sequence_nodes: {test_net.3:[CNode]4{[0]: ValueNode<PrimitivePy> MakeTuple， [1]: a， [2]: b}， elements_use_flags: {ptr: 0x5645cbc500c0， value: [const vector][1， 1]}}}\tThe function call stack (See file 'analyze_fail.dat' for more details):\t# 0 In file test.py(16)\t    a = grad(test_net)(x， y， sens_i)\t        ^\t```", "history": []}
{"prompt": "编译时报错“The params of function 'bprop' of Primitive or Cell requires the forward inputs as well as the 'out' and 'dout'”怎么办？", "response": "用户自定义的Cell的反向传播函数`bprop`，它的输入需要包含正向网络的输入，以及`out`和`dout`，例如：\t```python\tclass BpropUserDefinedNet(nn.Cell):\t        def __init__(self):\t            super(BpropUserDefinedNet， self).__init__()\t            self.zeros_like = P.ZerosLike()\t\t        def construct(self， x， y):\t            return x + y\t\t        def bprop(self， x， y， out， dout):\t            return self.zeros_like(out)， self.zeros_like(out)\t```", "history": []}
{"prompt": "编译时报错“There isn't any branch that can be evaluated”怎么办？", "response": "当出现There isn't any branch that can be evaluated 时，说明代码中可能出现了无穷递归或者时死循环，导致if条件的每一个分支都无法推导出正确的类型和维度信息。\t例如代码\t```python\tfrom mindspore import Tensor， ms_function， set_context， GRAPH_MODE\tfrom mindspore import dtype as mstype\tZERO = Tensor([0]， mstype.int32)\tONE = Tensor([1]， mstype.int32)\t@ms_function\tdef f(x):\t    y = ZERO\t    if x < 0:\t        y = f(x - 3)\t    elif x < 3:\t        y = x * f(x - 1)\t    elif x < 5:\t        y = x * f(x - 2)\t    else:\t        y = f(x - 4)\t    z = y + 1\t    return z\t\tdef test_endless():\t    set_context(mode=GRAPH_MODE)\t    x = Tensor([5]， mstype.int32)\t    f(x)\t\t```其中f(x)由于每一个if分支都没办法推导出正确的类型信息导致失败。", "history": []}
{"prompt": "编译时报错\"Exceed function call depth limit 1000\"怎么办？", "response": "当出现Exceed function call depth limit 1000 时，说明代码中出现了无穷递归死循环，或者是代码过于复杂，类型推导过程中导致栈深度超过设置的最大深度。\t此时可以通过设置context.set_context(max_call_depth = value)这样的方式更改栈的最大深度，并考虑简化代码逻辑或者检查代码中是否存在无穷递归或死循环。\t此外设置max_call_depth = value 虽然可以改变MindSpore的递归深度，但是此时也可能会超过系统栈的最大深度而出现段错误。此时可能还需要设置将系统栈深度进行设置。", "history": []}
{"prompt": "编译时报错“could not get source code”以及“Mindspore can not compile temporary source code in terminal. Please write source code to a python file and run the file.”是什么原因？", "response": "MindSpore编译网络时通过`inspect.getsourcelines(self.fn)`获取网络代码所在的文件，如果网络是编辑在命令行中的临时代码，那么会出现如标题所示的报错，需要将网络写在Python文件中去执行才能避免该错误。", "history": []}
{"prompt": "报错提示中的“Corresponding forward node candidate:”或“Corresponding code candidate:”是什么意思？", "response": "“Corresponding forward node candidate:”为关联的正向网络中的代码，表示该反向传播算子与该正向代码对应。“Corresponding code candidate:”表示该算子是由这些代码融合而来，其中分符“-”用以区分不同的代码。\t例如：\t- 算子FusionOp_BNTrainingUpdate_ReLUV2报错，打印了如下的代码行：\t\t    ```text\t    Corresponding code candidate:\t     - In file /home/workspace/mindspore/build/package/mindspore/nn/layer/normalization.py(212)/                return self.bn_train(x，/\t       In file /home/workspace/mindspore/tests/st/tbe_networks/resnet.py(265)/        x = self.bn1(x)/\t       In file /home/workspace/mindspore/build/package/mindspore/nn/wrap/cell_wrapper.py(109)/        out = self._backbone(data)/\t       In file /home/workspace/mindspore/build/package/mindspore/nn/wrap/cell_wrapper.py(356)/        loss = self.network(*inputs)/\t       In file /home/workspace/mindspore/build/package/mindspore/train/dataset_helper.py(98)/        return self.network(*outputs)/\t     - In file /home/workspace/mindspore/tests/st/tbe_networks/resnet.py(266)/        x = self.relu(x)/\t       In file /home/workspace/mindspore/build/package/mindspore/nn/wrap/cell_wrapper.py(109)/        out = self._backbone(data)/\t       In file /home/workspace/mindspore/build/package/mindspore/nn/wrap/cell_wrapper.py(356)/        loss = self.network(*inputs)/\t       In file /home/workspace/mindspore/build/package/mindspore/train/dataset_helper.py(98)/        return self.network(*outputs)/\t    ```\t\t    第一个分隔符的代码调用栈指向了网络脚本文件中第265行的“x = self.bn1(x)”，第二个分隔符的代码调用栈指向了网络脚本文件中第266行的“x = self.relu(x)”。可知，该算子FusionOp_BNTrainingUpdate_ReLUV2由这两行代码融合而来。\t\t- 算子Conv2DBackpropFilter报错，打印了如下的代码行：\t\t    ```text\t    In file /home/workspace/mindspore/build/package/mindspore/ops/_grad/grad_nn_ops.py(65)/        dw = filter_grad(dout， x， w_shape)/\t    Corresponding forward node candidate:\t     - In file /home/workspace/mindspore/build/package/mindspore/nn/layer/conv.py(266)/        output = self.conv2d(x， self.weight)/\t       In file /home/workspace/mindspore/tests/st/tbe_networks/resnet.py(149)/        out = self.conv1(x)/\t       In file /home/workspace/mindspore/tests/st/tbe_networks/resnet.py(195)/        x = self.a(x)/\t       In file /home/workspace/mindspore/tests/st/tbe_networks/resnet.py(270)/        x = self.layer2(x)/\t       In file /home/workspace/mindspore/build/package/mindspore/nn/wrap/cell_wrapper.py(109)/        out = self._backbone(data)/\t       In file /home/workspace/mindspore/build/package/mindspore/nn/wrap/cell_wrapper.py(356)/        loss = self.network(*inputs)/\t       In file /home/workspace/mindspore/build/package/mindspore/train/dataset_helper.py(98)/        return self.network(*outputs)/\t    ```\t\t    第一行是该算子的相应源码，该算子是反向算子，故由MindSpore实现。第二行提示此算子有关联的正向节点，第四行则指向了网络脚本文件第149行的“out = self.conv1(x)”。综上可知，算子Conv2DBackpropFilter是一个反向算子，相应的正向节点是一个卷积算子。", "history": []}
{"prompt": "什么是“JIT Fallback”？编译时报错“Should not use Python object in runtime”怎么办？", "response": "JIT Fallback是从静态图的角度出发考虑静态图和动态图的统一，希望静态图模式能够尽量多的支持动态图模式的语法，其借鉴了传统JIT编译的fallback的思路。编译静态图时，如果遇到不支持的语法，将会记录相关语句并生成解释节点，在后续处理中将相关语句fallback到Python解释器进行解释执行，从而支持该语法。JIT Fallback的环境变量开关是`DEV_ENV_ENABLE_FALLBACK`，默认使用JIT Fallback。\t当出现“Should not use Python object in runtime”和“We suppose all nodes generated by JIT Fallback would not return to outside of graph”的报错信息时，说明静态图模式代码中出现了错误使用语法，生成的解释节点在编译阶段无法正常解释执行，从而出现报错。当前JIT Fallback有条件地支持Graph模式的部分常量场景，同时需要符合MindSpore的编程语法，编写代码时请参考[静态图语法支持](https://www.mindspore.cn/docs/zh-CN/master/note/static_graph_syntax_support.html)。\t例如，在调用第三方库NumPy时，JIT Fallback支持`np.add(x， y)`和`Tensor(np.add(x， y))`的语法，但MindSpore不支持NumPy类型的返回值，将会出现报错。代码样例如下：\t```python\timport numpy as np\timport mindspore.nn as nn\tfrom mindspore import set_context， GRAPH_MODE\t\tset_context(mode=GRAPH_MODE)\t\tclass Net(nn.Cell):\t    def construct(self， x， y):\t        out = np.add(x， y)\t        return out\t\tnet = Net()\tout = net(1， 1)\t```执行结果如下：\t```text\tRuntimeError: mindspore/ccsrc/pipeline/jit/validator.cc:139 ValidateValueNode] Should not use Python object in runtime， node: ValueNode<InterpretedObject> InterpretedObject: '2'\t\tWe suppose all nodes generated by JIT Fallback not return to outside of graph.\t\t# In file test.py(9)\t        out = np.add(x， y)\t        ^\t```出现JIT Fallback相关的报错时，请根据[静态图语法支持](https://www.mindspore.cn/docs/zh-CN/master/note/static_graph_syntax_support.html)以及报错代码行，重新检视代码语法并修改。如果需要关闭JIT Fallback，可以设置`export DEV_ENV_ENABLE_FALLBACK=0`。", "history": []}
{"prompt": "编译时报错“Operator[AddN]  input(kNumberTypeBool，kNumberTypeBool) output(kNumberTypeBool) is not support. This error means the current input type is not supported， please refer to the MindSpore doc for supported types.”怎么办？", "response": "MindSpore当前对数据类型为bool的Tensor[后续简称Tensor(bool)]支持能力较弱，仅有少量算子支持Tensor(bool)类型的数据参与运算。若在正向图中使用了支持Tensor(bool)类型的算子且正向图语法正确，由于反向图求解全导数会引入`AddN`，`AddN`不支持Tensor(bool)类型，反向图运行就会抛出该异常。\t例如代码：\t```python\tfrom mindspore import set_context， ops， ms_function， Tensor， dtype\t\tset_context(save_graphs=True， save_graphs_path='graph_path')\t\t@ms_function\tdef test_logic(x， y):\t    z = x and y\t    return z and x\t\tx = Tensor(True， dtype.bool_)\ty = Tensor(True， dtype.bool_)\tgrad = ops.GradOperation(get_all=True)\tgrad_net = grad(test_logic)\tout = grad_net(x， y)\t```上述代码正向处理可以用公式表示为：`r = f(z， x)， z = z(x， y)` 对应的全导数公式为：`dr/dx = df/dz * dz/dx + df/dx`， 函数`f(z，x)`和`z(x，y)`均为逻辑运算符`and`； 正向图中的`and`算子支持Tensor(bool)类型，反向图求全导数时引入的`AddN`不支持Tensor(bool) 类型， 且该错误无法对应到具体的正向代码行。\t执行结果如下：\t```text\tTraceback (most recent call last):\t  File \"grad_fail.py\"， line 14， in <module>\t    out = grad_net(x， y)\t  File \"/usr/local/python3.7/lib/python3.7/site-packages/mindspore/common/api.py\"， line 307， in staging_specialize\t    out = _MindsporeFunctionExecutor(func， ms_create_time， input_signature， process_obj)(*args)\t  File \"/usr/local/python3.7/lib/python3.7/site-packages/mindspore/common/api.py\"， line 79， in wrapper\t    results = fn(*arg， **kwargs)\t  File \"/usr/local/python3.7/lib/python3.7/site-packages/mindspore/common/api.py\"， line 221， in __call__\t    phase = self.compile(args_list， arg_names， parse_method)\t  File \"/usr/local/python3.7/lib/python3.7/site-packages/mindspore/common/api.py\"， line 195， in compile\t    self.enable_tuple_broaden)\tTypeError: mindspore/ccsrc/runtime/device/cpu/kernel_select_cpu.cc:235 KernelNotSupportException] Operator[AddN]  input(kNumberTypeBool，kNumberTypeBool) output(kNumberTypeBool) is not support. This error means the current input type is not supported， please refer to the MindSpore doc for supported types.\tTrace:\tIn file /usr/local/python3.7/lib/python3.7/site-packages/mindspore/ops/composite/multitype_ops/add_impl.py(287)/    return F.addn((x， y))/\t```若遇到这类问题请去除对Tensor(bool)类型的使用，本例中将Tensor(bool)替换为bool即可解决问题。", "history": []}
{"prompt": "编译时报错“Side Effect Invalid: found unsupported syntax in graph mode， those side effect codes would be ignored:”怎么办？", "response": "如果在`Cell.construct`或者`ms_function`函数以及其调用的子函数里，使用了副作用算子，则要求所在函数不能直接返回常量值，包括最终返回值经过推导是常量的情况。由于函数返回常量时，编译器会优先把常量值以外的操作优化掉，导致其它操作看起来无效。对于非副作用的算子操作，忽略掉一般不会影响最终结果的正确性。但是如果包含了副作用算子的操作，忽略掉副作用算子往往跟用户期望相左。因此，对于出现函数返回值为常量，同时又包含副作用算子操作的情况，编译器会抛出异常，提示用户代码执行有可能无法符合预期，需要调整代码实现。\t例如代码：\t```python\tfrom mindspore.nn import Cell\t\tclass Demo(Cell):\t    def __init__(self):\t        super().__init__()\t\t    def construct(self， x):\t        print('print here...')\t        y = x[1]\t        y[1] = 9\t        return y\t\tx = [[1， 2， 3， 4]， [5， 6， 7， 8]]\tnet = Demo()\toutput = net(x)\tprint(output)\t```上述代码`y`经过推导后是一个常量值，整个函数可以被优化为直接返回常量值。除此以外的操作全部被优化掉，包括`print('print here...')`也会在编译时被忽略掉。由于`print`算子是副作用算子，其行为被删除后不符合预期，因此编译器会抛出错误提示用户。\t执行结果如下：\t```text\tTraceback (most recent call last):\t  File \"test_print_op.py\"， line 20， in <module>\t    output = net(x)\t  File \"/usr/local/python3.7/lib/python3.7/site-packages/mindspore/nn/cell.py\"， line 586， in __call__\t    out = self.compile_and_run(*args)\t  File \"/usr/local/python3.7/lib/python3.7/site-packages/mindspore/nn/cell.py\"， line 964， in compile_and_run\t    self.compile(*inputs)\t  File \"/usr/local/python3.7/lib/python3.7/site-packages/mindspore/nn/cell.py\"， line 937， in compile\t    _cell_graph_executor.compile(self， *inputs， phase=self.phase， auto_parallel_mode=self._auto_parallel_mode)\t  File \"/usr/local/python3.7/lib/python3.7/site-packages/mindspore/common/api.py\"， line 1086， in compile\t    result = self._graph_executor.compile(obj， args_list， phase， self._use_vm_mode())\tRuntimeError: mindspore/ccsrc/pipeline/jit/static_analysis/evaluator.cc:127 CheckSideEffectNodes] Side Effect Invalid: Found unsupported syntax in graph mode， those side effect codes would be ignored:\t-----\t# No. 1:\tIn file test_print_op.py(11)\t         print('print here...')\t         ^\t\t-----\t\tIf a function return a const value or inferred const value， the side effect node would be ignored.\tSo the codes may not run as the user's expectation， please fix it.\t\tIn this case， the const value '[[1， 2， 3， 4]， [5， 6， 7， 8]]' returns:\tIn file test_print_op.py(10)\t     def construct(self， a):\t     ^\t\tFor more information about this issue， please refer to https://www.mindspore.cn/search?inputValue=Side%20Effect%20Invalid\t```若遇到这类问题请去除副作用算子的调用，或者修改函数返回值不返回常量。", "history": []}
{"prompt": "在使用`ops.concat`算子时，因为数据规模有点大，导致报错`Error:Input and (output + workspace) num should <=192!`，可以怎么处理？", "response": "这种报错，主要为`ops.concat`算子提示`shape`过大。建议对`dataset`对象创建迭代器时可设置输出为`numpy`， 如下设置：\t```python\tgallaryloader.create_dict_iterator(output_numpy=True)\t```另外在上述后处理环节（非网络计算过程中，即非`construct`函数里面），可以采用`numpy`直接计算，如采用`numpy.concatenate`代替上述`ops.concat`进行计算。", "history": []}
{"prompt": "请问在静态图模式的`construct`函数里，如何把一个`tensor`中所含有的负数值全部去除掉？", "response": "建议使用`ops.clip_by_value`接口，把负数全变成0来进行计算。", "history": []}
{"prompt": "`TransData`算子的功能是什么，能否优化性能？", "response": "`TransData`算子出现的场景是: 如果网络中相互连接的算子使用的数据格式不一致（如NC1HWC0），框架就会自动插入`transdata`算子使其转换成一致的数据格式，然后再进行计算。 华为Ascend支持5D格式运算，通过`transdata`算子将数据由4D转为5D以提升性能。", "history": []}
{"prompt": "算子`Concat`拼接包含多个Tensor的元组出错，似乎传入的`tensor list`元素个数>=192就会报错。如果要`Concat`包含多个Tensor的元组，有什么较好的解决方案？", "response": "这个昇腾算子底层规格限制一次拼接的Tensor个数不能超过192个，可以尝试分开两次进行拼接。", "history": []}
{"prompt": "在使用`Conv2D`进行卷积定义的时候使用到了`group`的参数，`group`的值不是只需要保证可以被输入输出的维度整除即可了吗？`group`参数的传递方式是怎样的呢？", "response": "`Conv2D`算子是有这个约束条件的: 当`group`大于1 时，其值必须要与输入输出的通道数相等。不要使用`ops.Conv2D`，这个算子目前不支持`group`>1。目前MindSpore只有`nn.Conv2D`接口支持组卷积，但是有`group`要与输入输出的通道数相等的约束。", "history": []}
{"prompt": "MindSpore支持矩阵转置吗？", "response": "支持，请参考`mindspore.ops.Transpose`的[算子教程](https://www.mindspore.cn/docs/zh-CN/master/api_python/ops/mindspore.ops.Transpose.html#mindspore.ops.Transpose)。", "history": []}
{"prompt": "请问MindSpore能算给定任意一个`tensor`的方差吗？", "response": "mindspore目前暂无可以直接求出`tensor`方差的算子或接口。不过MindSpore有足够多的小算子可以支持用户实现这样的操作，你可以参考[class Moments(Cell)](https://www.mindspore.cn/docs/en/master/_modules/mindspore/nn/layer/math.html#Moments)来实现。", "history": []}
{"prompt": "`nn.Embedding`层与PyTorch相比缺少了`Padding`操作，有其余的算子可以实现吗？", "response": "在PyTorch中`padding_idx`的作用是将embedding矩阵中`padding_idx`位置的词向量置为0，并且反向传播时不会更新`padding_idx`位置的词向量。在MindSpore中，可以手动将embedding的`padding_idx`位置对应的权重初始化为0，并且在训练时通过`mask`的操作，过滤掉`padding_idx`位置对应的`Loss`。", "history": []}
{"prompt": "Operations中`Tile`算子执行到`__infer__`时`value`值为`None`，丢失了数值是怎么回事？", "response": "`Tile`算子的`multiples input`必须是一个常量（该值不能直接或间接来自于图的输入）。否则构图的时候会拿到一个`None`的数据，因为图的输入是在图执行的时候才传下去的，构图的时候拿不到图的输入数据。\t相关的资料可以看[静态图语法支持](https://www.mindspore.cn/docs/zh-CN/master/note/static_graph_syntax_support.html)。", "history": []}
{"prompt": "使用conv2d算子将卷积核设置为(3，10)，Tensor设置为[2，2，10，10]，在ModelArts上利用Ascend跑，报错: `FM_W+pad_left+pad_right-KW>=strideW`，CPU下不报错。", "response": "TBE(Tensor Boost Engine)算子是华为自研的Ascend算子开发工具，在TVM框架基础上扩展，进行自定义算子开发。上述问题是这个TBE算子的限制，x的width必须大于kernel的width。CPU的这个算子没有这个限制，所以不报错。", "history": []}
{"prompt": "请问MindSpore实现了反池化操作了吗？类似于`nn.MaxUnpool2d` 这个反池化操作？", "response": "目前 MindSpore 还没有反池化相关的接口。用户可以通过自定义算子的方式自行开发算子，详情请见[自定义算子](https://www.mindspore.cn/tutorials/experts/zh-CN/master/operation/op_custom.html)。", "history": []}
{"prompt": "使用ExpandDims算子报错: `Pynative run op ExpandDims failed`。具体代码:", "response": "```python\tcontext.set_context(mode=context.GRAPH_MODE，device_target='Ascend')\tinput_tensor=Tensor(np.array([[2，2]，[2，2]])，mindspore.float32)\texpand_dims=ops.ExpandDims()\toutput=expand_dims(input_tensor，0)\t```这边的问题是选择了Graph模式却使用了PyNative的写法，所以导致报错，MindSpore支持两种运行模式，在调试或者运行方面做了不同的优化:\t- PyNative模式: 也称动态图模式，将神经网络中的各个算子逐一下发执行，方便用户编写和调试神经网络模型。\t\t- Graph模式: 也称静态图模式或者图模式，将神经网络模型编译成一整张图，然后下发执行。该模式利用图优化等技术提高运行性能，同时有助于规模部署和跨平台运行。", "history": []}
{"prompt": "Ascend后端报错：`AI CORE` 和`AI CPU`中都找不到有效的`kernel info`这个Kernel Select Failed时，如何定位？", "response": "Ascend后端，算子有AI CORE算子和AI CPU算子之分，部分算子AI CORE支持，部分算子AI CPU支持，部分算子两者同时支持。根据报错信息：\t1. 如果`AI CORE`候选算子信息为空，则可能是在算子`check support`阶段，所有的算子信息均校验未通过。可以在日志中搜索关键字`CheckSupport`找到未通过的原因，根据具体信息修改shape或data type， 或者找开发人员进一步定位；\t2. 如果`AI CPU`候选算子信息不为空，或者`AI CORE`和`AI CPU`候选算子信息都不为空，则可能是用户给到该算子的输入数据类型不在候选列表中，在选择阶段被过滤掉导致，可以根据候选列表尝试修改该算子的输入data type。\t用户可以参考[官网教程](https://www.mindspore.cn/tutorials/zh-CN/master/advanced/pynative_graph/pynative.html)选择合适、统一的模式和写法来完成训练。", "history": []}
{"prompt": "MindSpore安装完成，执行训练时发现网络性能异常，权重初始化耗时过长，怎么办？", "response": "可能与环境中使用了`scipy 1.4`系列版本有关，通过`pip list | grep scipy`命令可查看scipy版本，建议改成MindSpore要求的`scipy`版本。版本第三方库依赖可以在`requirement.txt`中查看。\t<https://gitee.com/mindspore/mindspore/blob/{version}/requirements.txt>\t> 其中version替换为MindSpore具体的版本分支。", "history": []}
{"prompt": "导致Loss值不收敛或者精度不达标的原因有哪些呢，应该怎样定位调优？", "response": "可能导致Loss值不收敛或者精度问题的原因很多，推荐参考下面总结，逐一排查问题。\t[MindSpore模型精度调优实战（一）精度问题的常见现象、原因和简要调优思路](https://bbs.huaweicloud.com/forum/forum.php?mod=viewthread&tid=102750)\t[MindSpore模型精度调优实战（二）精度调试调优思路](https://bbs.huaweicloud.com/forum/forum.php?mod=viewthread&tid=106624)\t[MindSpore模型精度调优实战（三）常见精度问题简介](https://bbs.huaweicloud.com/forum/forum.php?mod=viewthread&tid=119271)", "history": []}
{"prompt": "请问想加载PyTorch预训练好的模型用于MindSpore模型finetune有什么方法？", "response": "需要把PyTorch和MindSpore的参数进行一一对应，因为网络定义的灵活性，所以没办法提供统一的转化脚本。\t一般情况下，CheckPoint文件中保存的就是参数名和参数值，调用相应框架的读取接口后，获取到参数名和数值后，按照MindSpore格式，构建出对象，就可以直接调用MindSpore接口保存成MindSpore格式的CheckPoint文件了。\t其中主要的工作量为对比不同框架间的parameter名称，做到两个框架的网络中所有parameter name一一对应(可以使用一个map进行映射)，下面代码的逻辑转化parameter格式，不包括对应parameter name。\t```python\timport torch\tfrom mindspore import Tensor， save_checkpoint\t\tdef pytorch2mindspore(default_file = 'torch_resnet.pth'):\t    # read pth file\t    par_dict = torch.load(default_file)['state_dict']\t    params_list = []\t    for name in par_dict:\t        param_dict = {}\t        parameter = par_dict[name]\t        param_dict['name'] = name\t        param_dict['data'] = Tensor(parameter.numpy())\t        params_list.append(param_dict)\t    save_checkpoint(params_list，  'ms_resnet.ckpt')\t```", "history": []}
{"prompt": "怎么将PyTorch的`dataset`转换成MindSpore的`dataset`？", "response": "MindSpore和PyTorch的自定义数据集逻辑是比较类似的，需要用户先定义一个自己的`dataset`类，该类负责定义`__init__`，`__getitem__`，`__len__`来读取自己的数据集，然后将该类实例化为一个对象（如: `dataset/dataset_generator`），最后将这个实例化对象传入`GeneratorDataset`(mindspore用法)/`DataLoader`(pytorch用法)，至此即可以完成自定义数据集加载了。而MindSpore在`GeneratorDataset`的基础上提供了进一步的`map`->`batch`操作，可以很方便的让用户在`map`内添加一些其他的自定义操作，并将其`batch`起来。\t对应的MindSpore的自定义数据集加载如下:\t```python\t# 1 Data enhancement，shuffle，sampler.\tclass Mydata:\t    def __init__(self):\t        np.random.seed(58)\t        self.__data = np.random.sample((5， 2))\t        self.__label = np.random.sample((5， 1))\t    def __getitem__(self， index):\t        return (self.__data[index]， self.__label[index])\t    def __len__(self):\t        return len(self.__data)\tdataset_generator = Mydata()\tdataset = ds.GeneratorDataset(dataset_generator， [\"data\"， \"label\"]， shuffle=False)\t# 2 Customized data enhancement\tdataset = dataset.map(operations=pyFunc， {other_params})\t# 3 batch\tdataset = dataset.batch(batch_size， drop_remainder=True)\t```", "history": []}
{"prompt": "其他框架的脚本或者模型怎么迁移到MindSpore？", "response": "关于脚本或者模型迁移，可以查询MindSpore官网中关于[迁移脚本](https://www.mindspore.cn/docs/zh-CN/master/migration_guide/migration_script.html)的介绍。", "history": []}
{"prompt": "MindConverter转换TensorFlow脚本报错提示`terminate called after throwing an instance of 'std::system_error'， what(): Resource temporarily unavailable， Aborted (core dumped)`", "response": "该问题由TensorFlow导致。脚本转换时，需要通过TensorFlow库加载TensorFlow的模型文件，此时TensorFlow会申请相关资源进行初始化，若申请资源失败（可能由于系统进程数超过Linux最大进程数限制），TensorFlow C/C++层会出现Core Dumped问题。详细信息请参考TensorFlow官方ISSUE，如下ISSUE仅供参考: [TF ISSUE 14885](https://github.com/tensorflow/tensorflow/issues/14885)， [TF ISSUE 37449](https://github.com/tensorflow/tensorflow/issues/37449)", "history": []}
{"prompt": "MindConverter是否可以在ARM平台运行？", "response": "MindConverter同时支持X86、ARM平台，若在ARM平台运行需要用户自行安装模型所需的依赖包和运行环境。", "history": []}
{"prompt": "为什么使用MindConverter进行模型转换需要很长时间（超过十分钟），而模型并不大？", "response": "MindConverter进行转换时，需要使用Protobuf对模型文件进行反序列化，请确保Python环境中安装的Protobuf采用C++后端实现，检查方法如下，若输出为Python，则需要安装采用C++实现的Python Protobuf（下载Protobuf源码并进入源码中的python子目录，使用python setup.py install --cpp_implementation进行安装）；若输出为cpp，转换过程仍耗时较长，请在转换前使用添加环境变量`export PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=cpp`。\t```python\tfrom google.protobuf.internal import api_implementation\t\tprint(api_implementation.Type())\t```", "history": []}
{"prompt": "使用.pb文件进行转换时，已确定`model_file`，`shape`，`input_nodes`，`output_nodes`均无误，并且环境中的依赖库已经正常安装，但是仍然报异常代码1000001，可能是什么原因？", "response": "请检查生成该.pb文件所使用的TensorFlow版本不高于用于转换时安装的TensorFlow版本，避免由于旧版本TensorFlow无法解析新版本生成的.pb文件，而导致的模型文件解析失败。", "history": []}
{"prompt": "出现报错信息`[ERROR] MINDCONVERTER: [BaseConverterError] code: 0000000， msg: {python_home}/lib/libgomp.so.1: cannot allocate memory in static TLS block`时，应该怎么处理？", "response": "该问题通常是由于环境变量导入不正确导致的。建议用户设置`export LD_PRELOAD={python_home}/lib/libgomp.so.1.0.0`这一环境变量，然后重新尝试进行转换。", "history": []}
{"prompt": "FAQ", "response": "本文档是openGauss常见问题指南。", "history": []}
{"prompt": "FAQ", "response": "如何清除编译过程中生成的临时文件。", "history": []}
{"prompt": "FAQ", "response": "如果在root用户下执行工具命令时，出现如下信息。", "history": []}
